"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"ABCD2345","webpage","","Center for History and New Media","Zotero Quick Start Guide","","","","","http://zotero.org/support/quick_start_guide","","","2016-09-13 16:12:22","2016-09-13 16:12:22","","","","","","","","","","","","","","","","","","","","","","","<p><strong>Welcome to Zotero!</strong></p> <p>View the Quick Start Guide to learn how to begin collecting, managing, citing, and sharing your research sources.</p> <p>Thanks for installing Zotero.</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FXIPVEGU","journalArticle","2010","Bowers, Alex J.","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Practical Assessment, Research & Evaluation","","1531-7714","","","School personnel currently lack an effective method to pattern and visually interpret disaggregated achievement data collected on students as a means to help inform decision making. This study, through the examination of longitudinal K-12 teacher assigned grading histories for entire cohorts of students from a school district (n=188), demonstrates a novel application of hierarchical cluster analysis and pattern visualization in which all data points collected on every student in a cohort can be patterned, visualized and interpreted to aid in data driven decision making by teachers and administrators. Additionally, as a proof-of-concept study, overall schooling outcomes, such as student dropout or taking a college entrance exam, are identified from the data patterns and compared to past methods of dropout identification as one example of the usefulness of the method. Hierarchical cluster analysis correctly identified over 80% of the students who dropped out using the entire student grade history patterns from either K-12 or K-8. (Contains 5 figures.)","2010-05","2016-09-15 14:53:13","2016-09-15 14:53:13","2014-09-24 19:31:29","","","7","15","","","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students","","","","","","","en","","","","","ERIC","","","<p>Notes</p> <ul> <li>No model to help decision making on disaggregated achievement data collection on students</li> <li>Grades may not be the best way to gauge learning, but teachers are often resistant to change</li> <li>Data driven decision making (3DM)</li> <li>Goal for 3DM should be to interrupt a decline in achievement early, before it results in future course failure <ul> <li>Predictive process is tough to gauge and do this properly</li> <li>Central aim, however, is for teachers to combat the previous by adopting hierarchical cluster analysis and heatmaps for use with teachers assigning grades and data driven decision making</li> <li>Figure three brings this together</li> </ul> </li> <li>Hierarchical cluster analysis (HCA) of k-6 data predicted 63% of students who would drop out, and HCA of K-12 and K-8 predicted 88.6% and 93.9% of students who would drop out.&nbsp; These numbers are drastic improvements in predicting students who will drop out.&nbsp; This can lead to interventions before this actually occurs.&nbsp;</li> </ul>","","http://eric.ed.gov/?id=EJ933686","","data; data analysis; Decision Making; Dropouts; Elementary School Students; Grades (Scholastic); Identification; MULTIVARIATE analysis; School Districts; Secondary School Students","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MPWH5VN8","journalArticle","2014","Grunspan, Daniel Z.; Wiggins, Benjamin L.; Goodreau, Steven M.","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","CBE-Life Sciences Education","",", 1931-7913","10.1187/cbe.13-08-0162","http://www.lifescied.org/content/13/2/167","Social interactions between students are a major and underexplored part of undergraduate education. Understanding how learning relationships form in undergraduate classrooms, as well as the impacts these relationships have on learning outcomes, can inform educators in unique ways and improve educational reform. Social network analysis (SNA) provides the necessary tool kit for investigating questions involving relational data. We introduce basic concepts in SNA, along with methods for data collection, data processing, and data analysis, using a previously collected example study on an undergraduate biology classroom as a tutorial. We conduct descriptive analyses of the structure of the network of costudying relationships. We explore generative processes that create observed study networks between students and also test for an association between network position and success on exams. We also cover practical issues, such as the unique aspects of human subjects review for network studies. Our aims are to convince readers that using SNA in classroom environments allows rich and informative analyses to take place and to provide some initial tools for doing so, in the process inspiring future educational studies incorporating relational data.","2014-06-20","2016-09-15 14:53:14","2016-09-15 14:53:14","2014-08-20 20:21:46","167-178","","2","13","","CBE Life Sci Educ","Understanding Classrooms through Social Network Analysis","","","","","","","en","","","","","www.lifescied.org","","","<p>Notes</p> <ul> <li>Social interactions is an unexplored area in undergraduate education</li> <li>Understanding those relationships can improve educators in unique ways and improve educational reform.&nbsp;</li> <li>SNA provides the toolkit for investigating questions involving relational data.</li> <li>This study creates observed networks between students while also testing for an association between network position and success on exams.&nbsp;</li> <li>&nbsp;Studies Goal: To convince readers that using SNA in classroom environments allows rich and informative analyses to take place and to provide some initial tools for doing so, in the process inspiring future educational studies incorporating relational data.</li> <li>Networks have a large impact on student behavior. <ul> <li><strong><em>Social Network Basics. </em></strong>SNA aims to understand the determinants, structure, and consequences of relationships be- tween actors. In other words, SNA helps us to understand how relationships form, what kinds of relational structures emerge from the building blocks of individual relationships between pairs of actors, and what, if any, the impacts are of these relationships on actors. <em>Actors</em>, also called <em>nodes</em>, can be individuals, organizations, websites, or any entity that can be connected to other entities. A group of actors and the connections between them make up a network.</li> <li>The importance of relationships and emergent structures formed by relationships makes SNA different from other re- search paradigms, which often focus solely on the attributes of actors. For example, traditional analyses may separate students into groups based on their attributes and search for disproportional outcomes based on those attributes. A social network perspective would focus instead on how individuals may have similar network positions due to shared attributes. These similar network positions may present the same social influences on both individuals, and these social influences may be an important part of the causal chain to the shared outcome. In situations in which a presence or absence of social support is suspected to be important to outcomes of interest, such as formal learning within a classroom, the SNA paradigm is appealing.</li> </ul> </li> <li>Networks change over time, and SNA can track that to gauge network efficacy within examination scores</li> <li>Correlating student performance to network position is one future use of SNA</li> <li>Educational networks are not exclusive to students.&nbsp; They can be used to link teachers, administrators, and teaching practices to identify key components of success within an educational institution.</li> <li>Networks are a simple yet powerful way of looking at the small and vital communities in every school and college.&nbsp;</li> </ul>","","http://www.lifescied.org/content/13/2/167","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AZFWCQMI","blogPost","2014","Young, Jeffrey R.","Why Students Should Own Their Educational Data","The Chronicle of Higher Education Blogs: Wired Campus","","","","http://chronicle.com/blogs/wiredcampus/why-students-should-own-their-educational-data/54329","","2014-08-21","2016-09-15 14:53:14","2016-09-15 14:53:14","2014-08-23 21:32:22","","","","","","","","","","","","","","","","","","","","","","<p>Notes</p> <ul> <li>Most learners have a jagged profile<strong></strong> <ul> <li>One student may have an affinity for science, but below-average reading skills.&nbsp; Since science books assume students are grading level, students who struggle to read also struggle in science.&nbsp; Science, in essence, becomes a reading test instead of a learning experience for science. <strong></strong></li> </ul> </li> <li>Author believes data can solve jagged profiles, by having customized learning.</li> <li>Statistical patterns are not indicative of the population</li> <li>Goal: For students to have access to there contextualized profile.&nbsp; This would include your performance and your learner profile across contexts.&nbsp; Currently everyone, but the user has access to their data.&nbsp; If students could have access to their own learning data across their educational tenure they can optimize their learning, by analyzing their own learning style and performing interventions accordingly,</li> </ul>","","http://chronicle.com/blogs/wiredcampus/why-students-should-own-their-educational-data/54329","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"28P8DNV6","conferencePaper","2012","Siemens, George; Baker, Ryan S. J. d.","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Proceedings of the 2Nd International Conference on Learning Analytics and Knowledge","978-1-4503-1111-3","","10.1145/2330601.2330661","http://doi.acm.org/10.1145/2330601.2330661","Growing interest in data and analytics in education, teaching, and learning raises the priority for increased, high-quality research into the models, methods, technologies, and impact of analytics. Two research communities -- Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK) have developed separately to address this need. This paper argues for increased and formal communication and collaboration between these communities in order to share research, methods, and tools for data mining and analysis in the service of developing both LAK and EDM fields.","2012","2016-09-15 14:53:14","2016-09-15 14:53:14","2015-01-16 03:15:55","252–254","","","","","","Learning Analytics and Educational Data Mining","","","","","ACM","New York, NY, USA","","","","","","ACM Digital Library","","","<p>Notes</p> <ul> <li>Educational Data Mining (EDM) &amp; Learning Analytics and Knowledge (LAK) have developed to address the need of growing interest in data and analytics in education, teaching, and learning raises the priority for increased, high-quality research into the models, methods, technologies, and impact of analytics.&nbsp;</li> <li>Paper argues communication and collaboration between the two fields: in things such as tools, research, and methods for data mining and analysis in the service of LAK and EDM.&nbsp;</li> <li>Emergence of big data in education holds promise for improving learning processes in education.</li> <li>Very large data sets are available, via repository, for public analysis.</li> <li>EDM brings together a inter-disciplinary community of computer scientists, learning scientists, psychometricians, and researchers.&nbsp;</li> <li>EDM and LAK are similar and have overlap.</li> <li>Difference 1: discovery prioritization.&nbsp; EDM has a focus on automated discover while LAK has a focus on human judgment.&nbsp; <ul> <li>In EDM models are used as the basis of automated adaption, while LAK models are designed to inform and empower instructors and learners.</li> </ul> </li> <li>Difference 2: EDM focuses on individual parts whereas LAK focuses on the model as a whole.&nbsp;</li> <li>EDM: Educational Data Mining is an emerging discipline, concerned with developing methods for exploring the unique types of data that come from educational settings, and using those methods to better understand students, and the settings that they learn in.</li> <li>LAK: The measurement, collection, analysis and reporting of data about learners and their contexts, for purposes of understanding and optimizing learning and the environments in which it occurs.</li> <li>To create collaboration it is recommended that each side disseminate their research to one another.&nbsp;</li> <li>EDM and LAK agree that data and analytics will transform all levels of education (primary, secondary, and post-secondary).</li> </ul>","","","","Collaboration; educational data mining; learning analytics and knowledge","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3WNXQAQJ","journalArticle","2008","Baker, Ryan S. J. d; Corbett, Albert T.; Roll, Ido; Koedinger, Kenneth R.","Developing a generalizable detector of when students game the system","User Modeling and User-Adapted Interaction","","0924-1868, 1573-1391","10.1007/s11257-007-9045-6","http://link.springer.com.ezp-prod1.hul.harvard.edu/article/10.1007/s11257-007-9045-6","Some students, when working in interactive learning environments, attempt to “game the system”, attempting to succeed in the environment by exploiting properties of the system rather than by learning the material and trying to use that knowledge to answer correctly. In this paper, we present a system that can accurately detect whether a student is gaming the system, within a Cognitive Tutor mathematics curricula. Our detector also distinguishes between two distinct types of gaming which are associated with different learning outcomes. We explore this detector’s generalizability, and find that it transfers successfully to both new students and new tutor lessons.","2008-08-01","2016-09-15 14:53:14","2016-09-15 14:53:14","2015-01-16 16:33:56","287-314","","3","18","","User Model User-Adap Inter","","","","","","","","en","","","","","link.springer.com.ezp-prod1.hul.harvard.edu","","","<p>Notes</p> <ul> <li>Some students game the system when working in interactive learning environments.&nbsp; This is done by exploiting properties of the system rather than by learning the material and trying to use that knowledge to answer questions correctly.</li> <li>The paper presents a system that detects students who are gaming the system, within math curricula.&nbsp;</li> <li>Latent response models were used as the statistical basis for the detector of harmful gaming.</li> <li>Latent response models have the advantage of easily and naturally integrating multiple data sources, at different grain sizes, into a single model</li> <li>They use four criteria to judge their gaming detector <ul> <li>Identifying which students game</li> <li>Accurately identifying when students game</li> <li>Increasing our knowledge about gaming</li> <li>Generalizing beyond the original training context</li> </ul> </li> <li>Their model was the best one three of the four criterions; the second was the only one where they were not the best.&nbsp; Thus they say that their model was the best.&nbsp;</li> <li>Future detectors may detect if a student using an intelligent tutoring system is idle, off task, and asking the teacher or another for help.&nbsp;</li> </ul> <p><strong>&nbsp;</strong></p>","","http://link.springer.com.ezp-prod1.hul.harvard.edu/article/10.1007/s11257-007-9045-6","","Behavior detection; Cognitive tutors; Education (general); Gaming the system; Generalizable models; Interactive learning environments; Latent response models; Machine learning; Management of Computing and Information Systems; Multimedia Information Systems; student modeling; User Interfaces and Human Computer Interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RPEBDBWT","book","2015","Zheng, Alice","Evaluating Machine Learning Models","","","","","http://www.oreilly.com/data/free/evaluating-machine-learning-models.csp?intcmp=il-data-free-lp-lgen_free_reports_page","Data science today is a lot like the Wild West: there’s endless opportunity and excitement, but also a lot of chaos and confusion. If you’re new to data science and applied machine learning, evaluating a machine-learning model can seem pretty overwhelming...","2015-09","2016-09-15 14:53:14","2016-09-15 14:53:14","2015-12-15 18:26:39","","","","","","","","","","","","O'Reily Media","Sebastopol, CA","","","","","","","","","<p>Notes</p> <ul> <li>Classification metrics is about predicting class labels given input data<strong></strong></li> <li>Accuracy measure how often the classifier makes the correct prediction.<strong></strong> <ul> <li>Accuracy = (# of correct predictions) / (# of total data points)<strong></strong></li> </ul> </li> <li>A confusion matrix shows a more detailed breakdown of correct and incorrect classifications for each class</li> <li>AUC = Area under the curve</li> <li>ROC = Receiver operating characteristic</li> <li>The curve shows the sensitivity of the classifier by plotting the rate of true positives to the rate of false positives.&nbsp; In other words it should you how many correct positive classifications can be gained as you allow for more and more false positives.</li> <li>Classifier: A model, which predicts the class value from other explanatory attributes.&nbsp; For example, you can predict drop out rates from a student’s performance (such as grade and attendance) in a given course.</li> <li>Precision-recall is popular for classification tasks <ul> <li>This uses two metrics.&nbsp;</li> <li>Precision answers the question, “Out of the items that the ranker/classifier predicted to be relevant, how many are truly relevant?” <ul> <li>Precision = (# of happy correct answers) / (# of total items returned by ranker)</li> </ul> </li> <li>Whereas, recall answers the question, “Out of all the items that are truly relevant, how many are found by the ranker/classifier?” <ul> <li>Recall = (# of happy correct answers) / (# of total relevant items)</li> </ul> </li> </ul> </li> <li>In a regression task, the model learns to predict numeric scores</li> <li>Outliers can skew results, and they must be approach with caution.&nbsp; Every situation asks for something different, so you may want to remove them but you may also want to look at applying new models for them.</li> <li>Be on the lookout for data skew.&nbsp; This can affect results. Data skew is when one kind of data is much more rare than others, or when there are very large or very small outliers that could drastically change the metric</li> <li>R Software Packages: Metrics package</li> </ul> <p>&nbsp;</p>","","http://www.oreilly.com/data/free/evaluating-machine-learning-models.csp?intcmp=il-data-free-lp-lgen_free_reports_page","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ESCHKCJB","blogPost","2015","Leong, B; Polonetsky, J","Why Opting Out of Student Data Collection Isn’t the Solution","EdSurge","","","","https://www.edsurge.com/news/2015-03-16-why-opting-out-of-student-data-collection-isn-t-the-solution","In every privacy debate across every industry, the same questions arise about the rights of individuals to “opt-out” of their data being collected or used. So it should come as no surprise that the “when” and “how” of parent and student opt-outs of education data collection or use has become a robust","2015-03-16","2016-09-15 14:53:14","2016-09-15 14:53:14","2016-01-16 16:31:25","","","","","","","","","","","","","","","","","","","","","","<p>Notes</p> <ul> <li>Data helps students <ul> <li>Data is needed for schools to function <ul> <li>Record grades, eligibility for subsidized lunch, etc.</li> </ul> </li> <li>Data shows schools which methods are performing well over time, which can lead to improvements</li> <li>Opting out disables a schools’ ability to gauge how good of an education they are providing</li> </ul> </li> <li>Students should consider opting out when their data is being used for purposes unrelated to education activities: marketing, selling data, etc.</li> <li>Why opting out is not the solution <ul> <li>Opting out takes away the opportunities for educational improvement.&nbsp;</li> <li>Opting out should only be an opportunity to decline use of secondary use of educational data, not an opportunity to avoid resolution of education policy issues that affect all students.&nbsp; It is on policy holders to make this happen</li> </ul> </li> </ul>","","https://www.edsurge.com/news/2015-03-16-why-opting-out-of-student-data-collection-isn-t-the-solution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3D3W85MJ","videoRecording","2015","Educause","Why Is Measuring Learning So Difficult?","","","","","https://www.youtube.com/watch?v=_iv8A1pHNYA","Several higher education learning and assessment professionals discuss the difficulties of measuring learning.","2015-08-17","2016-09-15 14:53:14","2016-09-15 14:53:14","2016-01-17 18:50:57","","","","","","","","","","","","","","","","","","","YouTube","","","<p>Notes</p> <ul> <li>Learning is multidimensional.&nbsp;</li> <li>Problem: You have to simplify learning to much in order to capture data (understanding that we can use).</li> <li>Learning is too broad.&nbsp; Can’t measure it in a psychometric way.</li> <li>In fields like the humanities it is extremely hard to gauge learning, whereas in mathematics it is much simpler.&nbsp;</li> <li>Analytics shouldn’t just be a diagnosis of what’s happening now, but also a way to showcase what else is possible (within a student’s learning).</li> </ul> <p>&nbsp;</p>","","","","Assessment; Education; educational assessment; EDUCAUSE; Higher Education; learners; Learning; Teaching and learning","","","","","","","","","","","","","","","","","","","","","470 seconds","","","","","","","","","","","","","","","","","","","","","","","","",""
"C39FCW2U","webpage","2016","Weinersmith, Zach","Saturday Morning Breakfast Cereal","","","","","http://www.smbc-comics.com/index.php?id=3978","","2016-01-05","2016-09-15 14:53:14","2016-09-15 14:53:14","2016-01-18 18:17:09","","","","","","","","","","","","","","","","","","","","","","<p>Notes</p> <ul> <li>Showcases the potential danger of LA<strong></strong></li> <li>In this cartoon they depict elite engineers disassembling and reassembling clocks as children.&nbsp; So schools base their entire curriculum about clocks.&nbsp; Eliminating every subject.&nbsp; Later the schools realized that the elite engineers only liked clocks as kids, not anything else.&nbsp; Basically this shows that basing decisions on data alone can lead to catastrophe if not used in the right context.&nbsp; Context + Data Analysis = Better Decision Making.&nbsp; <strong></strong></li> </ul>","","http://www.smbc-comics.com/index.php?id=3978","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9RFXNCD7","conferencePaper","2014","Clow, Doug","Data wranglers: human interpreters to help close the feedback loop","Proceedings of the Fourth International Conference on Learning Analytics And Knowledge","","","","","","2014","2016-09-15 14:53:14","2016-09-15 14:53:14","","49–53","","","","","","","","","","","ACM","","","","","","","","","","<p>Notes</p> <ul> <li>LA is about entailing a feedback loop.&nbsp; Actionable intelligence is produced from data and their contexts, and interventions are made with the aim of improving learning.</li> <li>Actionable intelligence must be met with EDM tools.&nbsp;</li> <li>This is a case study at OU (open university).&nbsp;</li> <li>Short-term goal was to make actionable recommendations.&nbsp; Long-term goal was to drive systematic improvement through single and double-loop learning, and through the support and development of a Community of Practice at the Open University.</li> <li>Data wranglers were tasked with making sense of the data and producing recommendations.</li> <li>The data wranglers were worked with four main data sources. <ul> <li>Survey feedback</li> <li>Activity data</li> <li>Delivery data</li> <li>Aggregated completion</li> </ul> </li> <li>At the end of the case study overall performance actually decreased, but this could be due to the massive change in a short period of time.</li> <li>Feedback form the stakeholders was positive</li> <li>Data quality was an issue with the case study was misinterpretation of the data.</li> <li>The data wranglers approach is high cost, in terms of time, but has promise to yield high understanding.&nbsp;</li> </ul>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5JUEF7Q9","magazineArticle","2015","Kucirkova, Natalia; FitzGerald, Elizabeth","Zuckerberg is ploughing billions into 'personalised learning' – why?","The Conversation","","","","http://theconversation.com/zuckerberg-is-ploughing-billions-into-personalised-learning-why-51940","Zuckerburg wants to plough billions into personalised learning, but his way may not be the right way.","2015-12-09","2016-09-15 14:53:14","2016-09-15 14:53:14","2016-01-18 19:14:05","","","","","","","","","","","","","","","","","","","","","","<p>Notes</p> <ul> <li>Zuckerburg believes personalized learning will solve many of education’s current woes.&nbsp; This is one of four areas his fund ($65 billion) will focus on.<strong></strong></li> <li>For him personalized learning is about teachers “working with students to customize instruction to meet the student’s individual needs and interests”.<strong></strong></li> <li>Dangers of personalized learning <ul> <li>If you give students only what they’re interested in you create specialists and few generalists</li> <li>This may help students while they are learning, but the real world does not accommodate to what suites you best; it’s about what suites the company you’re working for best</li> <li>Student preferences are not fixed.&nbsp; In order to predict content relevant information human-directed input is necessary, not simply automation</li> <li>Making sure student data is not misused (privacy risk)</li> </ul> </li> <li>Where personalized learning could help<strong></strong> <ul> <li>This method gives students a sense of ownership and relevance.&nbsp; <strong></strong></li> </ul> </li> <li>Author recommends a compromised approach.&nbsp; An example would be McGraw Hill.&nbsp; They allow educators to choose between the adaptive or customized study plans.&nbsp; The first adapts to the learner’s pace, while the latter provides a course modified according to the teacher’s knowledge of what fits the students best.</li> <li>Author states that personalized learning should be used to adapt and customize a pupil’s learning according to their needs as well as teachers’ experience and school requirements.</li> </ul>","","https://theconversation.com/zuckerberg-is-ploughing-billions-into-personalised-learning-why-51940","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FFP86WM9","videoRecording","2015","Georgia Tech","Feature Selection","","","","","https://www.youtube.com/watch?v=8CpRLplmdqE","","2015-02-23","2016-09-15 14:53:14","2016-09-15 14:53:14","2016-01-18 19:18:06","","","","","","","","","","","","Youtube","","","","","","","","","","<p>Notes</p> <ul> <li>Knowledge discovery (this is about human beings)<strong></strong> <ul> <li>Interpretability (of the features) and insight <strong></strong></li> </ul> </li> <li>Curse of dimensionality (this is about machines and machine learning algorithms): The amount of data you need grows exponentially in the number of features you have.&nbsp; It would be nice if you have fewer features.&nbsp; Which is why feature selection is important.&nbsp; This makes the learning problem easier.&nbsp; <strong></strong></li> <li>The goal of feature selection is to use a bunch of features that you may think is important and implement an algorithm to get to <em>just</em> the important features.&nbsp; If you can do that well you can understand your data better and you will also have an easier learning problem.&nbsp; <strong></strong></li> </ul>","","https://www.youtube.com/watch?v=8CpRLplmdqE","","","","","","","","","","","","","","","Udacity","","","","","","","","3:13","","","","","","","","","","","","","","","","","","","","","","","","",""
"V4M3HCR4","bookSection","2016","Hanneman, R.A.; Riddle, M.","Chapter 1: Social Network Data","Introduction to Social Network Methods","","","","http://faculty.ucr.edu/~hanneman/nettext/C1_Social_Network_Data.html","","2016-01-18","2016-09-15 14:53:14","2016-09-15 14:53:14","2016-01-18 20:17:24","","","","","","","","","","","","","","","","","","","","","","<p>Notes</p> <ul> <li>Conventional data consists of rectangular measurements.&nbsp; These are attributes, variables, or measures.&nbsp; Figure 1.1</li> <li>Network data consists of square measurements.&nbsp; These are observations and relationships.&nbsp; Figure 1.2</li> <li>Network analysts look at the data structure holistically.&nbsp; Also how individual choices give rise to more holistic patterns</li> <li>Nodes aka actors.</li> <li>Relations aka edges</li> <li>Network data are defined by actors and by relations.</li> <li>Many different sampling ties.&nbsp; One extreme is full network methods (this requires information from the entire population).&nbsp; This is really expensive and time consuming.&nbsp; On another end you can use a method that costs less, but not as detailed.</li> <li>Snowball method is a method where actors are asked to name all their ties.&nbsp; If no new actors are named that marks the end, if not the process continues on and on.&nbsp; This can be useful when tracking down special populations (subsets of people within large populations).</li> <li>Ties between actors can be measured at ‘different levels of measurement.”</li> <li>Scales of measurement: They are important because different kinds of scales have different mathematical properties, and call for different algorithms in describing patterns and testing inferences about them. <ul> <li>Binary measure of relations</li> <li>Multiple-category nominal measures of relations</li> <li>Grouped ordinal measures of relations</li> <li>Full-rank ordinal measures of relations</li> <li>Interval measures of relations</li> </ul> </li> <li>Social network analysis is more a branch of ""mathematical"" sociology than of ""statistical or quantitative analysis,"" though social network analysts most certainly practice both approaches. The distinction between the two approaches is not clear-cut. Mathematical approaches to network analysis tend to treat the data as ""deterministic."" That is, they tend to regard the measured relationships and relationship strengths as accurately reflecting the ""real"" or ""final"" or ""equilibrium"" status of the network. Mathematical types also tend to assume that the observations are not a ""sample"" of some larger population of possible observations; rather, the observations are usually regarded as the population of interest. Statistical analysts tend to regard the particular scores on relationship strengths as stochastic or probabilistic realizations of an underlying true tendency or probability distribution of relationship strengths. Statistical analysts also tend to think of a particular set of network data as a ""sample"" of a larger class or population of such networks or network elements -- and have a concern for the results of the current study would be reproduced in the ""next"" study of similar samples.</li> </ul>","","http://faculty.ucr.edu/~hanneman/nettext/C1_Social_Network_Data.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F7QD4DH4","webpage","2014","Groelmund, Garrett","RStudio Cheat Sheets","RStudio","","","","https://www.rstudio.com/resources/cheatsheets/","","2014-08-01","2016-09-15 14:53:14","2016-09-15 14:53:14","2016-01-19 21:17:28","","","","","","","","","","","","","","","","","","","","","","<ul> <li>Quick reference guide for writing report with R Markdown, within R.&nbsp;</li> </ul>","","http://shiny.rstudio.com/articles/rm-cheatsheet.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NRBTFAZC","conferencePaper","2013","san Pedro, Maria Ofelia; Baker, Ryan; Bowers, Alex; Heffernan, Neil","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","Educational Data Mining 2013","","","","","","2013","2016-09-15 14:53:14","2016-09-15 14:53:14","","","","","","","","","","","","","","","","","","","","","","","<p>Notes</p> <ul> <li>Middle school is when a student starts to be conscious about academic achievement and thinks about college attendance.<strong></strong></li> <li>Many students are using educational software.&nbsp; Detectors can be implemented within the software to intervene when necessary.&nbsp; The detectors will be used for specific aspects of student learning and engagement.<strong></strong></li> <li>The detectors in this study correctly predict whether a student would attend college 68.6% of the time.&nbsp; <strong></strong></li> <li>In the past detectors were limited to a few variables of disengagement: failing grades, problem behaviors, and non-attendance.&nbsp; Educational software offers many more variables as it tracks log files.&nbsp; The log files can gauge boredom, carelessness, frustration, and many more variables.&nbsp; Thus giving a more accurate detector.<strong></strong> <ul> <li>A multiple-predictor logistic regression model was fitted to predict whether a student will enroll in college from a combination of features of his or her student affect, engagement, knowledge and other information on student usage (the proportion of correct actions, and the number of first attempts on problems made by the student, a proxy for overall usage) of a tutoring system during middle school.</li> </ul> </li> <li>Gaming the system and boredom are low indicators if a student will attend college.<strong></strong></li> <li>A high indicator was success in middle school mathematics<strong></strong></li> <li>Study found what people already know.&nbsp; Good grades and academic achievement are good indicators on a students’ likelihood of attending college.&nbsp; However they found some new things.&nbsp; Such as if proper interventions are provided through educational software, it can have large effects.&nbsp; Thus, if this can be correctly implemented into educational software it is possible that more students may attend college.&nbsp; <strong></strong></li> </ul>","/Users/Devan/Library/Application Support/Firefox/Profiles/rwud9k2r.default/zotero/storage/QIZTF5HA/EDM2013_SBBH.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GCIV4KG8","journalArticle","2012","Greller, Wolfgang; Drachsler, Hendrik","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Journal of Educational Technology & Society","","1176-3647","","http://www.jstor.org/stable/jeductechsoci.15.3.42","ABSTRACT With the increase in available educational data, it is expected that Learning Analytics will become a powerful means to inform and support learners, teachers and their institutions in better understanding and predicting personal learning needs and performance. However, the processes and requirements behind the beneficial application of Learning and Knowledge Analytics as well as the consequences for learning and teaching are still far from being understood. In this paper, we explore the key dimensions of Learning Analytics (LA), the critical problem zones, and some potential dangers to the beneficial exploitation of educational data. We propose and discuss a generic design framework that can act as a useful guide for setting up Learning Analytics services in support of educational practice and learner guidance, in quality assurance, curriculum development, and in improving teacher effectiveness and efficiency. Furthermore, the presented article intends to inform about soft barriers and limitations of Learning Analytics. We identify the required skills and competences that make meaningful use of Learning Analytics data possible to overcome gaps in interpretation literacy among educational stakeholders. We also discuss privacy and ethical issues and suggest ways in which these issues can be addressed through policy guidelines and best practice examples.","2012","2016-09-15 14:53:14","2016-09-15 14:53:14","2016-09-03 18:55:41","42-57","","3","15","","Journal of Educational Technology & Society","Translating Learning into Numbers","","","","","","","","","","","","JSTOR","","","<p>Notes</p> <p>&nbsp;</p> <ul> <li>More available education data à LA will become a powerful means to inform and support learners/teacher/institutions in better understanding and predicting personal learning needs and performance. <ul> <li>Processes and requirements are still far from being understood</li> </ul> </li> <li>Paper discusses generic framework for setting up LA in education.&nbsp;</li> <li>Main driver for use of data in education.&nbsp; To improve the quality, effectiveness, and efficiency of the learning process.</li> <li>Personalized learning has the potential to reduce delivery costs while also creating more effective learning experiences, accelerating competence development, and increasing collaboration between learners.</li> <li>Six dimensions of LA (Figure 1) <ul> <li>Internal limitations <ul> <li>Competences</li> <li>Acceptance</li> </ul> </li> <li>External limitations <ul> <li>Conventions</li> <li>Norms</li> </ul> </li> <li>Instruments <ul> <li>Technology</li> <li>Algorithm</li> <li>Theories</li> <li>Other</li> </ul> </li> <li>Stakeholders <ul> <li>Institution</li> <li>Teachers</li> <li>Learners</li> <li>Other</li> </ul> </li> <li>Objectives <ul> <li>Prediction</li> <li>Reflection</li> </ul> </li> <li>Data <ul> <li>Open</li> <li>Protected</li> </ul> </li> </ul> </li> <li>Objectives of LA <ul> <li>Reflection <ul> <li>Self-evaluation</li> </ul> </li> <li>Prediction <ul> <li>Predict and model learner activities</li> </ul> </li> </ul> </li> <li>Most educational data from institutions are protected and not available.&nbsp; Thus LA cannot be used.</li> <li>Many datasets have erroneous information, thus polluting the dataset with meaningless data.&nbsp; This makes it very difficult for secondary use, analysis. Data cleaning takes up a lot of time.</li> <li>Ethical and privacy issues are a concern in LA</li> <li>Social network analysis may always not be the best way to present information.&nbsp; Context is always important when choosing a LA methodological approach.</li> <li>Within this framework no other dimensions should be added.&nbsp; In addition no dimensions should be deleted as the authors find every dimension valuable to the success of the framework.</li> <li>Personalized learning is meant to be the evolution of a one-size fits all approach to learning.&nbsp;</li> <li>LA should take a bottom-up approach with the focus on the learners to minimize the inherent dangers (privacy, student manipulation, reinforcing of segregation, etc.) of LA.&nbsp;</li> <li>LA can make invisible learning patterns visible, which can lead to new insights.</li> <li>Data analysis can have unwanted consequences if not used with the necessary care</li> <li>Education should not be built on LA approaches alone, but instead as a method to offer more options and opportunities within the field.&nbsp;</li> </ul>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A4CSJBAQ","bookSection","2006","Kay, Judy; Maisonneuve, Nicolas; Yacef, Kalina; Reimann, Peter","The Big Five and Visualisations of Team Work Activity","Intelligent Tutoring Systems","978-3-540-35159-7 978-3-540-35160-3","","","http://link.springer.com/chapter/10.1007/11774303_20","We have created a set of novel visualisations of group activity: they mirror activity of individuals and their interactions, based upon readily available authentic data. We evaluated these visualisations in the context of a semester long software development project course. We give a theoretical analysis of the design of our visualizations using the framework from the “Big 5” theory of team work as well as a qualitative study of the visualisations and the students’ reflective reports. We conclude that these visualisations provide a powerful and valuable mirroring role with potential, when well used, to help groups learn to improve their effectiveness.","2006-06-26","2016-09-15 14:53:14","2016-09-15 14:53:14","2016-09-03 19:10:12","197-206","","","","","","","","","","","Springer Berlin Heidelberg","","en","©2006 Springer-Verlag Berlin Heidelberg","","","","link.springer.com","","","<p>Notes</p> <ul> <li>Big five components of teamwork<strong></strong> <ul> <li>Team Leadership: ability to direct and coordinate other team members’ activities, assess team performance, assign tasks, develop team knowledge and skills, motivate team members, plan and organize, and establish a positive atmosphere.</li> <li>Mutual performance monitoring: ability to develop common understandings of the team environment and apply appropriate task strategies to accurately monitor teammate performance.</li> <li>Backup behavior: ability to anticipate other team members’ needs through accurate knowledge about their responsibilities. Includes the ability to shift workload among members to achieve balance during high periods of workload or pressure.</li> <li>Adaptability: ability to adjust strategies based on information gathered from the environment through the use of backup behavior and reallocation of intra-team re- sources. Altering a course of action or team repertoire in response to changing conditions (internal or external).</li> <li>Team orientation: propensity to take others’ behavior into account during group interaction and belief in importance of team goal over individual members’ goals.</li> </ul> </li> <li>In order for these five components to receive optimal performance three additional <em>coordinating mechanisms </em>must be in place <ul> <li>Shared mental models: An organizing knowledge structure of the relationships among the tasks the team is engaged in and how the team members will interact.</li> <li>Mutual trust: The shared belief that team members will perform their roles and protect the interests of their teammates.</li> <li>Closed-loop communication: The exchange of information between a sender and a receiver irrespective of the medium.</li> </ul> </li> <li>Case study tracks teams using the big five and provide groups with visualizations in return.&nbsp;&nbsp; The visualizations mirror information pertaining to the components of teamwork for the groups.&nbsp;</li> <li>Three visualizations <ul> <li>Activity Radar</li> <li>Interaction Network</li> <li>Wattle Tree</li> </ul> </li> <li>There were patterns between visualizations and team performance.&nbsp;</li> <li>In order to utilize visualizations you should not take them as rules (you have to or should do this), but instead take them as recommendations.&nbsp; You can use them, within the context of the team to optimize performance.&nbsp; The interpretations should be left for the team members to make decisions accordingly.&nbsp; Leaving normative decisions to groups may have motivational effects and may also lead to a more stability within the team.</li> </ul>","","https://link.springer.com/chapter/10.1007/11774303_20","","Artificial Intelligence (incl. Robotics); Computers and Education; Information Systems Applications (incl. Internet); Multimedia Information Systems; User Interfaces and Human Computer Interaction","Ikeda, Mitsuru; Ashley, Kevin D.; Chan, Tak-Wai","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2A5PIX82","journalArticle","2015","Konstan, Joseph A.; Walker, J. D.; Brooks, D. Christopher; Brown, Keith; Ekstrand, Michael D.","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","ACM Trans. Comput.-Hum. Interact.","","1073-0516","10.1145/2728171","http://doi.acm.org/10.1145/2728171","","2015-04","2016-09-15 14:53:15","2016-09-15 14:53:15","2016-09-03 20:38:02","10:1–10:23","","2","22","","","Teaching Recommender Systems at Large Scale","","","","","","","","","","","","ACM Digital Library","","","<p>Notes</p> <ul> <li>Coursera course about recommender systems.&nbsp; Both for free and for credit.&nbsp; Course was offered in purely online format and blended format (on campus using Coursera).&nbsp; <strong></strong></li> <li>The study tracks students through the course<strong></strong></li> <li>The main predictor of knowledge gain was effort in the course<strong></strong></li> <li>Main predictor of student completion was a student’s intent to complete<strong></strong></li> <li>Blended students did just as well or better than purely online students</li> <li>Knowledge gains did not correlate to any demographic</li> <li>In my opinion, the study found the obvious.&nbsp;&nbsp; Intent and effort will almost always correlate with success in the course.&nbsp; The study has data to back this up, but these findings were intuitive.&nbsp;</li> <li>The course requires a lot of effort, so it is tough to maintain.&nbsp; Opening assignments require substantial infrastructure</li> </ul>","","","","learning assessment; Massively Online Open Course (MOOC)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UG8KR9SJ","bookSection","2013","Desmarais, Michel C.; Naceur, Rhouma","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Artificial Intelligence in Education","978-3-642-39111-8 978-3-642-39112-5","","","http://link.springer.com/chapter/10.1007/978-3-642-39112-5_45","Uncovering the right skills behind question items is a difficult task. It requires a thorough understanding of the subject matter and of the cognitive factors that determine student performance. The skills definition, and the mapping of item to skills, require the involvement of experts. We investigate means to assist experts for this task by using a data driven, matrix factorization approach. The two mappings of items to skills, the expert on one side and the matrix factorization on the other, are compared in terms of discrepancies, and in terms of their performance when used in a linear model of skills assessment and item outcome prediction. Visual analysis shows a relatively similar pattern between the expert and the factorized mappings, although differences arise. The prediction comparison shows the factorization approach performs slightly better than the original expert Q-matrix, giving supporting evidence to the belief that the factorization mapping is valid. Implications for the use of the factorization to design better item to skills mapping are discussed.","2013-07-09","2016-09-15 14:53:15","2016-09-15 14:53:15","2016-09-03 20:44:11","441-450","","","","","","","","","","","Springer Berlin Heidelberg","","en","©2013 Springer-Verlag Berlin Heidelberg","","","","link.springer.com","","","<p>Notes</p> <ul> <li>Uncovering the right skills behind question items is a difficult task.&nbsp; <strong></strong></li> <li>It requires a thorough understanding of the subject matter and of the cognitive factors that determine student performance. The skills definition, and the mapping of item to skills, require the involvement of experts</li> <li>ALS factorization method offers a promising means of deriving Q-matrices from data given an expert defined Q-matrix to start with.&nbsp; <strong></strong></li> <li>ALS Q-matrix derived generates slightly better predictive item outcome performance.&nbsp; This gives support to the belief that the factorization mapping is valid.&nbsp; <strong></strong></li> <li>A small number of errors will not affect the method’s capacity to derive “better” Q-matrices (as defined by their predictive power) and make useful hints for enhancements.&nbsp;</li> <li>Study was limited to one Q-matrix expert.&nbsp; More studies should be done with more experts in other domains to better understand the results and assess the value of the method.<strong></strong></li> </ul>","","https://link.springer.com/chapter/10.1007/978-3-642-39112-5_45","","alternating least squares matrix factorization; Artificial Intelligence (incl. Robotics); Cognitive modeling; Computers and Education; Educational Technology; Information Systems Applications (incl. Internet); latent skills; Pedagogic Psychology; skills assessment; Student models; User Interfaces and Human Computer Interaction","Lane, H. Chad; Yacef, Kalina; Mostow, Jack; Pavlik, Philip","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KWGH6IX3","book","2015","Matsuda, Noboru; Furukawa, Tadanobu; Bier, Norman; Faloutsos, Christos","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","","","","","http://eric.ed.gov/?id=ED560513","How can we automatically determine which skills must be mastered for the successful completion of an online course? Large-scale online courses (e.g., MOOCs) often contain a broad range of contents frequently intended to be a semester's worth of materials; this breadth often makes it difficult to articulate an accurate set of skills and knowledge (i.e., a skill model, or the QMatrix). We have developed an innovative method to discover skill models from the data of online courses. Our method assumes that online courses have a pre-defined skill map for which skills are associated with formative assessment items embedded throughout the online course. Our method carefully exploits correlations between various parts of student performance, as well as in the text of assessment items, to build a superior statistical model that even outperforms human experts. To evaluate our method, we compare our method with existing methods (LFA) and human engineered skill models on three Open Learning Initiative (OLI) courses at Carnegie Mellon University. The results show that (1) our method outperforms human-engineered skill models, (2) skill models discovered by our method are interpretable, and (3) our method is remarkably faster than existing methods. These results suggest that our method provides a significant contribution to the evidence-based, iterative refinement of online courses with a promising scalability. [For complete proceedings, see ED560503.]","2015-06","2016-09-15 14:53:15","2016-09-15 14:53:15","2016-09-03 20:48:57","","","","","","","Machine Beats Experts","","","","","International Educational Data Mining Society","","en","","","","","ERIC","","","<p>Notes</p> <ul> <li>Claims that they have developed an innovative method to discover skill models from the data of online courses.&nbsp; This is under the assumption that the online course has a pre-defined skill map for which skills are associated with formative assessment items embedded throughout the online course.</li> <li>Their method is eEPIPHANY.&nbsp; This is a collection of data mining techniques for automatic discovery of skill models from online course data.&nbsp; The predictive power is based on cross-validation.&nbsp; The method can either find a Q-matric by itself or refine a given Q-matrix.&nbsp;</li> <li>Feature Extraction <ul> <li>Matrix Factorization strategy</li> <li>Bag of Words strategy</li> </ul> </li> <li>To showcase the methods efficiency and effectiveness it was applied to an actual online course</li> <li>They found that it was an efficient, practical and quick method to automatically discover skill models from online course data without human interaction. It also found that it finds skill models better than human-crafted ones</li> </ul>","","http://eric.ed.gov/?id=ED560513","","Automation; Comparative Analysis; Correlation; data; Formative Evaluation; models; Online Courses; Skills","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NFD9E5E6","conferencePaper","2008","Cortez, Paulo; Silva, Alice Maria Gonçalves","Using data mining to predict secondary school student performance","Proceedings of 5th Annual Future Business Technology Conference","978-90-77381-39-7","","","http://repositorium.sdum.uminho.pt/handle/1822/8024","Although the educational level of the Portuguese population has improved in the last decades, the statistics keep Portugal at Europe’s tail end due to its high student failure rates. In particular, lack of success in the core classes of Mathematics and the Portuguese language is extremely serious. On the other hand, the fields of Business Intelligence (BI)/Data Mining (DM), which aim at extracting high-level knowledge from raw data, offer interesting automated tools that can aid the education domain. The present work intends to approach student achievement in secondary education using BI/DM techniques. Recent real-world data (e.g. student grades, demographic, social and school related features) was collected by using school reports and questionnaires. The two core classes (i.e. Mathematics and Portuguese) were modeled under binary/five-level classification and regression tasks. Also, four DM models (i.e. Decision Trees, Random Forest, Neural Networks and Support Vector Machines) and three input selections (e.g. with and without previous grades) were tested. The results show that a good predictive accuracy can be achieved, provided that the first and/or second school period grades are available. Although student achievement is highly influenced by past evaluations, an explanatory analysis has shown that there are also other relevant features (e.g. number of absences, parent’s job and education, alcohol consumption). As a direct outcome of this research, more efficient student prediction tools can be be developed, improving the quality of education and enhancing school resource management.","2008-04","2016-09-15 14:53:15","2016-09-15 14:53:15","2016-09-04 01:23:19","","","","","","","","","","","","EUROSIS","Porto, Spain","eng","openAccess","","","","repositorium.sdum.uminho.pt","","","<p>Notes</p> <ul> <li>Case study in Portugal</li> <li>Portugal is at the tail end of Europe’s high student failure rates.&nbsp; This is primarily true about the two core subjects, math and Portuguese.&nbsp;</li> <li>Data mining and business intelligence was implemented to attempt to predict student performance.</li> <li>They found that achievement is highly influenced by past evaluations.&nbsp; They achievement is also influenced by number of absences, parent’s job and education, and alcohol consumption.</li> <li>A high predictive accuracy was achieved if the first and second school periods were given</li> <li>This study was done offline, but has possibilities for online learning environments.&nbsp; If it is done online, an automatic feature selection feature could be implemented. However, irrelevant information could hamper this.&nbsp; You need to find a way to minimize irrelevant information before you can automate this online.&nbsp;</li> <li>The study states that additional research should be done to understand why some variables affect student performance, but I’m sure someone has done this somewhere.&nbsp; It is no surprise that alcohol affects student performance, and it is also no surprise that a student’s family environment (parent’s education and job) has an impact (overall) on a student’s academic performance.</li> </ul>","","http://repositorium.sdum.uminho.pt/handle/1822/8024","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","5th Annual Future Business Technology Conference","","","","","","","","","","","","","","",""
"HBKFRH5X","videoRecording","2016","Georgia Tech","Cross Validation","","","","","https://www.youtube.com/watch?v=sFO2ff-gTh0","","2016-09-09","2016-09-15 14:53:15","2016-09-15 14:53:15","2016-09-09 19:37:11","","","","","","","","","","","","Youtube","","","","","","","","","","<p>Notes</p> <ul> <li>Cross validation: Find a way to predict values in the testing set<strong></strong></li> <li>Goal: Use a model that is complex enough to fit the data without causing problems to the test set</li> <li>Is there something we can use in the training set to act like its in the test set<strong></strong> <ul> <li>You can take some of the training data and pretend it’s the test set, and this wouldn’t be cheating because there’s nothing wrong in pretending<strong></strong></li> <li>Split training data into folds<strong></strong></li> <li>Then average the check (goodness of fit) to calculate the average error.&nbsp; You do this for multiple combinations, and you choose the model that has the lowest average error.&nbsp;</li> </ul> </li> </ul>","","https://www.youtube.com/watch?v=sFO2ff-gTh0","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NAEFUKCZ","webpage","","","Passing the Privacy Test as Student Data Laws Take Effect (EdSurge News)","EdSurge","","","","https://www.edsurge.com/news/2016-01-12-passing-the-privacy-test-as-student-data-laws-take-effect","On January 1, 2016, “ 	SOPIPA”—the recently passed California student data privacy law that defines how edtech companies can use student data became effective. About 25 other states have passed similar laws that are already in effect, or will become effective.  At the same time, more than 200 sc","","2016-12-11 03:11:17","2016-12-11 03:11:17","2016-12-11 03:11:17","","","","","","","","","","","","","","","","","","","","","","<p>Notes</p> <ul> <li>SOIPA (Senate Bill No. 1177 CHAPTER 839) passed in California and 25 other states. <ul> <li>For the purposes of this section, “operator” means the operator of an Internet Web site, online service, online application, or mobile application with actual knowledge that the site, service, or application is used primarily for K–12 school purposes and was designed and marketed for K–12 school purposes.</li> <li>An operator shall not knowingly engage in any of the following activities with respect to their site, service, or application:</li> </ul> </li> </ul> <ol> <li>Engage in targeted advertising on the operator’s site, service, or application, or (B) target advertising on any other site, service, or application when the targeting of the advertising is based upon any information, including covered information and persistent unique identifiers, that the operator has acquired because of the use of that operator’s site, service, or application described in subdivision (a).</li> <li>Use information, including persistent unique identifiers, created or gathered by the operator’s site, service, or application, to amass a profile about a K–12 student except in furtherance of K–12 school purposes.</li> <li>Sell a student’s information, including covered information. This prohibition does not apply to the purchase, merger, or other type of acquisition of an operator by another entity, provided that the operator or successor entity continues to be subject to the provisions of this section with respect to previously acquired student information.</li> <li>Disclose covered information unless the disclosure is made.</li> </ol> <ul> <li>Student privacy restrictions are limited to the “data generated while the student is using an educational product or service implemented by the school, but not while the student is doing general web browsing or personal activities unrelated to school.”</li> <li>De-identified data can be used for product improvement, but not for advertising.</li> </ul>","; /Users/Devan/Library/Application Support/Firefox/Profiles/rwud9k2r.default/zotero/storage/MET29SU2/2016-01-12-passing-the-privacy-test-as-student-data-laws-take-effect.html","https://www.edsurge.com/news/2016-01-12-passing-the-privacy-test-as-student-data-laws-take-effect?utm_content=bufferc0042&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B5SZ527M","webpage","","","data-wrangling-cheatsheet - data-wrangling-cheatsheet.pdf","","","","","http://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf","","","2016-12-11 03:15:16","2016-12-11 03:15:16","2016-12-11 03:14:36","","","","","","","","","","","","","","","","","","","","","","<ul> <li>Tidyr and dplyr cheat sheet in R.&nbsp; <strong></strong></li> <li>Shows you how to tidy data, reshape data, subset observations (rows), subset variables (columns), summarize data, make new variables, combine data sets, and group data.&nbsp; <strong></strong></li> </ul>","/Users/Devan/Library/Application Support/Firefox/Profiles/rwud9k2r.default/zotero/storage/9C6SZT65/data-wrangling-cheatsheet.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R2VRZQP8","journalArticle","1994","Corbett, Albert T.; Anderson, John R.","Knowledge tracing: Modeling the acquisition of procedural knowledge","User Modeling and User-Adapted Interaction","","0924-1868, 1573-1391","10.1007/BF01099821","http://link.springer.com/article/10.1007/BF01099821","This paper describes an effort to model students' changing knowledge state during skill acquisition. Students in this research are learning to write short programs with the ACT Programming Tutor (APT). APT is constructed around a production rule cognitive model of programming knowledge, called theideal student model. This model allows the tutor to solve exercises along with the student and provide assistance as necessary. As the student works, the tutor also maintains an estimate of the probability that the student has learned each of the rules in the ideal model, in a process calledknowledge tracing. The tutor presents an individualized sequence of exercises to the student based on these probability estimates until the student has ‘mastered’ each rule. The programming tutor, cognitive model and learning and performance assumptions are described. A series of studies is reviewed that examine the empirical validity of knowledge tracing and has led to modifications in the process. Currently the model is quite successful in predicting test performance. Further modifications in the modeling process are discussed that may improve performance levels.","1994-12-01","2016-12-11 03:42:17","2016-12-11 03:42:17","2016-12-11 03:42:17","253-278","","4","4","","User Model User-Adap Inter","Knowledge tracing","","","","","","","en","","","","","link.springer.com","","","<p>Notes</p> <ul> <li>Students re-learning to write short paragraphs wit the ACT Programming Tutor (APT).&nbsp; APT is constructed around a production rule cognitive model of programming knowledge, called ideal student model.&nbsp; As the student works, the tutor also maintains an estimate of the probability that the student has learned each of the rules in the ideal model, in a process called knowledge tracing.<strong></strong> <ul> <li>The study was successful at predicting performance, but a future implication would be to improve student performance<strong></strong></li> </ul> </li> <li>The goal in knowledge tracing is to estimate the student’s knowledge and ensure with a high probability that each rule is in the learned state.&nbsp; <strong></strong> <ul> <li>It may prove more cost effective to directly assess and remediate students' knowledge of key declarative concepts prior to practice, rather than trying to tease apart alternative rule formulations during practice.</li> </ul> </li> <li>They believe it is impossible to further the success of their research (predicting student performance) by manipulating incentive on testing, providing additional procedural practice or by monitoring and remediating student’s knowledge of key declarative concepts.&nbsp; <strong></strong></li> </ul>","/Users/Devan/Library/Application Support/Firefox/Profiles/rwud9k2r.default/zotero/storage/6PX72IVW/Corbett and Anderson - 1994 - Knowledge tracing Modeling the acquisition of pro.pdf; /Users/Devan/Library/Application Support/Firefox/Profiles/rwud9k2r.default/zotero/storage/R5MVWXM8/BF01099821.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q7ETH867","videoRecording","2015","ColumbiaLearn","Big Data in Education 4.2 Bayesian Knowledge Tracing","","","","","https://www.youtube.com/watch?v=_7CtthPZJ70&feature=youtu.be","","2015-07-20","2016-12-11 03:42:59","2016-12-11 03:42:59","2016-12-11 03:42:59","","","","","","","","","","","","","","","","","","","YouTube","","","<p>Notes</p> <ul> <li>Bayesian Knowledge Tracing is a method for knowledge inference</li> <li>BKT is a classic approach for measuring tightly defined skill in online learning.</li> <li>Key goal of BKT is to measure how well a student knows a specific skill (knowledge component) at a specific time.&nbsp; Based on their past history of performance with that skill/KC <ul> <li>Skills should be tightly defined</li> <li>Goal is not to measure the overall skill for a broadly defined construct, such as arithmetic.&nbsp; But instead to measure a specific skill or knowledge component, such as addition of two-digit numbers where no carrying is needed.</li> </ul> </li> <li>Typical use of BKT <ul> <li>Assess a student’s knowledge of skill/KC.&nbsp; Based on a sequence of items that are dichotomously scored.&nbsp; Where each item corresponds to a single skill</li> <li>Where the student can learn on each item, due to help, feedback, scaffolding, etc.</li> </ul> </li> <li>Key assumptions of BKT <ul> <li>Each item must involve a single latent trait or skill</li> <li>Each skill has four parameters</li> <li>From these parameters, and the patterns of success and failures the student has had on each relevant skill so far.</li> <li>We can compute latent knowledge P(Ln), and the probability P(CORR) that the learner will get the item correct.</li> <li>Two state learning model (either skill is either learned or unlearned) <ul> <li>This is clearly wrong, as partial knowledge exists.&nbsp; The most important question is not if an approach is right or wrong, but whether or not if it works; and BKT has been successful in certain areas</li> </ul> </li> <li>In problem-solving, the student can learn a skill at each opportunity to apply the skill</li> <li>A student does not forget a skill, once they know it <ul> <li>Obviously wrong, but as stated earlier this is not super important.</li> </ul> </li> <li>Model assumptions <ul> <li>If the student knows a skill, there is still some chance the student will slip and make a mistake</li> <li>If the student does not know a skill, there is still some chance the student will guess correctly.</li> </ul> </li> </ul> </li> <li>BKT Notes <ul> <li>Only uses the first problem attempt on each item</li> <li>This throws our a lot of information, but it uses the clearest information</li> </ul> </li> <li>Conceptual Idea Behind Knowledge Tracing <ul> <li>Knowing a skill generally leads to correct performance</li> <li>Correct performance implies that a student knows the relevant skill</li> <li>Hence, y looking at whether a student’s performance is correct, we can infer whether they know the skill</li> </ul> </li> <li>Knowledge tracing <ul> <li>Primary goal is to predict knowledge</li> <li>But knowledge is a latent trait</li> <li>So we instead check our knowledge predictions by checking how well the model predicts performance</li> </ul> </li> </ul> <p>&nbsp;</p>","","","","","","","","","","","","","","","","","","","","","","","","","724 seconds","","","","","","","","","","","","","","","","","","","","","","","","",""
"6AXGI5X4","videoRecording","2015","ColumbiaLearn","Big Data in Education 6.1 Learning Curves","","","","","https://www.youtube.com/watch?v=Mr17Z0nZUQc&feature=youtu.be","","2015-07-28","2016-12-11 03:44:02","2016-12-11 03:44:02","2016-12-11 03:44:02","","","","","","","","","","","","","","","","","","","YouTube","","","<p>Notes</p> <ul> <li>Visualization: Showing data in a meaningful fashion.&nbsp; Avoid distorting the data.&nbsp;</li> <li>One form of visualization is the learning curve.</li> <li>Learning curve assumptions <ul> <li>Student is practicing the same skill several times in (approximately) the same fashion.</li> <li>Similar methods and considerations apply to situations where the students is recalling the same knowledge several times</li> <li>We have some way to measure student performance</li> </ul> </li> <li>Power of learning: Performances (both speed and accuracy) improves with a power function. <ul> <li>Can be applied in simple domains (pressing correct button or stimulus), complex problem-solving domains (math and programming), and real-world domains (cigar making in factories).</li> </ul> </li> <li>Normal learning is when an asymptote forms over time.&nbsp; Not a graph that goes up and down.&nbsp; If it’s up and down that could mean a student already knows it or isn’t learning anything.</li> <li>Uses of the learning curves <ul> <li>To understand how (and whether) a skill is being learned across students</li> <li>To study and refine item-skill mappings in educational software</li> </ul> </li> </ul>","","","","","","","","","","","","","","","","","","","","","","","","","504 seconds","","","","","","","","","","","","","","","","","","","","","","","","",""
"3BRQNQGC","videoRecording","2015","ColumbiaLearn","Big Data in Education 6.3 Scatter Plots","","","","","https://www.youtube.com/watch?v=oTiixxmh9-Q&feature=youtu.be","","2015-07-28","2016-12-11 03:44:05","2016-12-11 03:44:05","2016-12-11 03:44:05","","","","","","","","","","","","","","","","","","","YouTube","","","<p>Notes</p> <ul> <li>Show relationship between two variables.</li> <li>They don’t scale well to large data sets.&nbsp; They are better off for smaller data sets.&nbsp; It’s hard to tell if there are trends if there is too much data (creates blobs).&nbsp; In addition if the data is too granular it may not to identify anything.&nbsp;</li> <li>Heat maps do better with large-scale data</li> <li>Heat maps can do more than scatterplots.&nbsp; They can judge intensity, and density (which scatterplots can’t). <ul> <li>Bowers, 2012 example with student success</li> </ul> </li> <li>Parameter space maps: special case of heat maps.&nbsp; Used to look at the goodness of carious parameters, particularly for Bayesian Knowledge Tracing (BKT).</li> <li>Simply, there are a lot of alternatives to scatterplots.&nbsp; Especially when you are dealing with very large data sets.</li> </ul>","","","","","","","","","","","","","","","","","","","","","","","","","406 seconds","","","","","","","","","","","","","","","","","","","","","","","","",""
"7IVJZJGI","videoRecording","2015","ColumbiaLearn","Big Data in Education 6.4 State Space Diagrams","","","","","https://www.youtube.com/watch?v=WI1AVcpCYgk&feature=youtu.be","","2015-07-28","2016-12-11 03:44:08","2016-12-11 03:44:08","2016-12-11 03:44:08","","","","","","","","","","","","","","","","","","","YouTube","","","<p>Notes</p> <ul> <li>State Space Diagrams: Visualizations of all the states that the learning system can have during a problem.&nbsp; Another term for this diagram is students learning pathways or interaction networks<strong></strong> <ul> <li>State = Complete characterization of the situation<strong></strong></li> </ul> </li> <li>Can be used for complex systems<strong></strong></li> <li>Used to <strong></strong> <ul> <li>Study specific student trajectories<strong></strong></li> <li>See which paths end up being productive<strong></strong></li> <li>See which paths are rare, despite being productive<strong></strong></li> <li>Make recommendations (hints) to students based on their path<strong></strong></li> </ul> </li> </ul>","","","","","","","","","","","","","","","","","","","","","","","","","241 seconds","","","","","","","","","","","","","","","","","","","","","","","","",""
"HIINZMVZ","videoRecording","2015","ColumbiaLearn","Big Data in Education 7.1 Clustering","","","","","https://www.youtube.com/watch?v=mgXm3AwLxP8&feature=youtu.be","","2015-08-07","2016-12-11 03:45:04","2016-12-11 03:45:04","2016-12-11 03:45:04","","","","","","","","","","","","","","","","","","","YouTube","","","<p>Notes</p> <ul> <li>Clustering is a type of <em>Structure Discovery </em>algorithm</li> <li>Within clustering <ul> <li>You have a large number of data points</li> <li>You want to find what structure there is among the data points</li> <li>You don’t know anything a priori about the structure</li> <li>Clustering tries to find data points that “group together”</li> </ul> </li> <li>Clustering can be used with thousands of data sets</li> <li>K-means clustering (one of the clustering algorithms)</li> <li>To do clustering the first thing you need to do is decide/identify how many clusters you are going to use.</li> <li>We use centroids to identify clusters within data points to showcase the divisions within the space</li> <li>Convergence (8 min 20 seconds has an example of convergence): Move the centroids towards the center of the data points within the cluster, which changes the location of the clusters because the center of the clusters change.&nbsp; You should repeat the process until the centroids stop moving. <ul> <li>Convergence occurs once the data points stop moving.&nbsp;</li> </ul> </li> <li>If you choose centroids that are really close together you are not going to get good clusters. <ul> <li>You could run your analysis multiple times, choosing different starting points to combat this</li> </ul> </li> <li>Clustering efficacy is often dependent on the number clusters (starting points) and initial positioning you start with.&nbsp; Which is why we randomized restart with new positions to make sure we don’t get unlucky once.&nbsp;</li> <li>How do we pick which final position to go with? <ul> <li>Next lecture validation and selection of k</li> </ul> </li> </ul>","","","","","","","","","","","","","","","","","","","","","","","","","820 seconds","","","","","","","","","","","","","","","","","","","","","","","","",""
"NS7TWFGV","videoRecording","2015","ColumbiaLearn","Big Data in Education 7.2 Validation and Selection","","","","","https://www.youtube.com/watch?v=B9dvJYwBfmk&feature=youtu.be","","2015-08-07","2016-12-11 03:45:07","2016-12-11 03:45:07","2016-12-11 03:45:07","","","","","","","","","","","","","","","","","","","YouTube","","","<p>Notes</p> <ul> <li>How do we choose k? <ul> <li>Distortion (aka Mean Squared Deviation) <ul> <li>Works for choosing randomized restarts.&nbsp; It does not work for choosing cluster size</li> </ul> </li> <li>Penalize models with more clusters, according to how much extra fit would be expected from the additional clusters. <ul> <li>You can use Bayesian Information Criterion or Akaike Information Criterion</li> </ul> </li> <li>How do you use information criterion <ul> <li>Assesses how much fit would be spuriously expected from a random N centroids</li> <li>Asses how much fit you actually had</li> <li>Find the difference</li> <li>How many clusters <ul> <li>Try several values of k</li> <li>Find best fitting set of cluster for each value of k</li> <li>Choose k with best value of BIC or AIC</li> </ul> </li> </ul> </li> <li>Alternate approach to choosing clusters <ul> <li>One question you should ask when choosing clusters is, why am I conducting cluster analysis.&nbsp;</li> <li>If you goal is to just discover qualitatively interesting patterns in the data, you may want to do something simpler than using an information criterion. <ul> <li>Add clusters until you don’t get interesting new clusters</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p><strong>&nbsp;</strong></p>","","","","","","","","","","","","","","","","","","","","","","","","","322 seconds","","","","","","","","","","","","","","","","","","","","","","","","",""
"94ESIT8S","videoRecording","2015","ColumbiaLearn","Big Data in Education 7.6 Knowledge Inference: Q-Matrix Knowledge Structure","","","","","https://www.youtube.com/watch?v=oFSV6-opnws&feature=youtu.be","","2015-08-10","2016-12-11 03:45:50","2016-12-11 03:45:50","2016-12-11 03:45:50","","","","","","","Big Data in Education 7.6 Knowledge Inference","","","","","","","","","","","","YouTube","","","<p>Notes</p> <ul> <li>A table where rows are items and columns are skills<strong></strong></li> <li>The Q-Matrix is also called a <em>knowledge component (KC)</em> model or a <em>skilled item mapping</em><strong></strong></li> <li>&nbsp;You can get a skill-item mapping by<strong></strong> <ul> <li>Automatic model discovery: Learn the mapping between items and skills solely from the data<strong></strong> <ul> <li>One popular algorithm is by Barnes, Bitzer and Vouk<strong></strong> <ul> <li>For each number of skill, the algorithm will be run a certain number of times, with a different (random) initial assignment of items to skills</li> <li>This process is continued to a predetermined number of times, or until a pass results in no change.&nbsp; This avoids local minima</li> <li>A model’s degree of error is based on how many item-student pairs the prediction gets wrong</li> </ul> </li> </ul> </li> <li>Hand-development and refinement: Original way Q-Matrices were created.&nbsp; In this method a domain expert creates the Q-Matrix using knowledge engineering<strong></strong> <ul> <li>Strategies for Q-Matrix Refinement<strong></strong> <ul> <li>Try to smooth learning curves<strong></strong> <ul> <li>A learning curve shows the relationship between amount of practice and performance<strong></strong></li> <li>Spikes in learning curves often imply that two (or more) skills are being treated as a single skill<strong></strong></li> </ul> </li> <li>Look for skills with no apparent learning<strong></strong></li> <li>Look for problems with unexpected error rates<strong></strong></li> </ul> </li> </ul> </li> <li>Hybrid approaches<strong></strong></li> </ul> </li> </ul>","","","","","","","","","","","","","","","","","","","","","","","","","527 seconds","","","","","","","","","","","","","","","","","","","","","","","","",""
"UAQNM9HX","videoRecording","2015","ColumbiaLearn","Big Data in Education 1.1 Introduction","","","","","https://www.youtube.com/watch?v=dc5Nx3tyR8g&feature=youtu.be","","2015-06-22","2016-12-11 03:46:32","2016-12-11 03:46:32","2016-12-11 03:46:32","","","","","","","","","","","","","","","","","","","YouTube","","","<p>Notes</p> <ul> <li>Methods for exploring big data in education, called educational data mining or learning analytics</li> <li>Types of EDM <ul> <li>Prediction: Develop a model, which can infer a single aspect of data (predicted variable) from some combination of other aspects of the data (predictor variables). <ul> <li>Classification</li> <li>Regression</li> <li>Latent Knowledge Estimation</li> </ul> </li> <li>Structure Discovery: Find structure and patterns in the data that emerge “naturally.” <ul> <li>Clustering</li> <li>Factor Analysis</li> <li>Domain Structure Discovery</li> <li>Network Analysis</li> </ul> </li> <li>Relationship mining: Discover relationships between variables in a data set with many variables. <ul> <li>Association rule mining</li> <li>Correlation mining</li> <li>Sequential pattern mining</li> <li>Casual data mining</li> </ul> </li> <li>Distillation of data for human judgment</li> <li>Discover with models: The use of a pre-existing model.</li> </ul> </li> </ul>","","","","","","","","","","","","","","","","","","","","","","","","","417 seconds","","","","","","","","","","","","","","","","","","","","","","","","",""
"MZ4WZKTA","videoRecording","2015","ColumbiaLearn","Big Data in Education 1.3 Classifiers, Part 1","","","","","https://www.youtube.com/watch?v=k9Z4ibzH-1s&feature=youtu.be","","2015-07-07","2016-12-11 03:46:35","2016-12-11 03:46:35","2016-12-11 03:46:35","","","","","","","","","","","","","","","","","","","YouTube","","","<p>Notes</p> <ul> <li>Classification is a type of prediction model.&nbsp; There is something you want to predict (“the label”).&nbsp; Within this you want to predict is categorical, such as… <ul> <li>Drop out or not</li> <li>Correct or wrong</li> </ul> </li> <li>Labels come from <ul> <li>School records</li> <li>Survey data</li> <li>In-software performance</li> <li>Log files</li> <li>Test data</li> </ul> </li> <li>Within classification.&nbsp; Associated with each label are a set of features, which maybe you can use to predict the label</li> <li>The basic idea of a classifier is to determine which features, in which combination, can predict the label</li> <li>Some useful algorithms <ul> <li>Step regression <ul> <li>This is not step-wise regression</li> <li>Used for binary classification (0,1).&nbsp;</li> <li>Fits a linear regression function <ul> <li>With an arbitrary cut-off</li> <li>Sets parameters</li> <li>Assigns a weight to each parameter</li> <li>Computes a numerical values</li> <li>Then all values below cut off are treated as 0, and all values greater than or equal to the cut off are treated as 1.</li> </ul> </li> </ul> </li> <li>Logistic regression <ul> <li>Another algorithm for binary classification (0,1)</li> <li>Given a specific set of values of predictor variables</li> <li>Fits logistic function to data to find out the frequency/odds of a specific value of the dependent variable</li> <li>This algorithm is relatively conservative.</li> <li>This algorithm is good where changes in value of predictor variables have predictable effects on probability of predicted variables class</li> </ul> </li> <li>J48/C4.5 Decision Trees <ul> <li>Can handle both numerical and categorical predictor variables</li> <li>Repeatedly looks for variables which best splits the data in terms of predictive power for each variable</li> <li>Later prunes out branches that have low predictive power</li> <li>&nbsp;</li> </ul> </li> <li>JRIP Decision Rules</li> <li>K* Instance-Based Classifiers</li> <li>Etc.</li> </ul> </li> <li>Decision trees are good for interaction effects.&nbsp; They are better than step regression and logistic regression.</li> </ul>","","","","","","","","","","","","","","","","","","","","","","","","","636 seconds","","","","","","","","","","","","","","","","","","","","","","","","",""
"AGSS9KR3","videoRecording","2015","ColumbiaLearn","Big Data in Education 1.4 Classifiers Part 2","","","","","https://www.youtube.com/watch?v=8X0UlMShss4&feature=youtu.be","","2015-06-30","2016-12-11 03:46:38","2016-12-11 03:46:38","2016-12-11 03:46:38","","","","","","","","","","","","","","","","","","","YouTube","","","<p>Notes</p> <ul> <li>Decision Rules (A type of classification algorithm): Sets of it rules which you check in order <ul> <li>Generating rules can depend on the algorithm or the person creating the rules</li> <li>This algorithm is good when multi-level interactions are common, just like decision trees</li> </ul> </li> <li>K* (Another type of classification algorithm): Predicts a data point from neighboring data points <ul> <li>Weights points more strongly if they are nearby</li> <li>Good when data is very divergent (when there is not easy patterns, but clumps)</li> <li>Intractable to find general rules</li> <li>It sometimes works when nothing else works.</li> <li>Has been useful detecting emotions from log files</li> <li>Big Drawback, you need the whole dataset</li> </ul> </li> <li>&nbsp;Conservative algorithms don’t over-fit to the data.&nbsp; Over-fit: where they fit to the noise in the data as well as the signal.&nbsp;</li> <li>Neural Networks: Composes extremely complex relationships through combining perceptrons <ul> <li>Finds very complicated models</li> <li>For most education data neural networks have not historically produced the best solutions.&nbsp; It simply does not work very often.</li> </ul> </li> </ul>","","","","","","","","","","","","","","","","","","","","","","","","","496 seconds","","","","","","","","","","","","","","","","","","","","","","","","",""
"92CSZFFD","videoRecording","2015","ColumbiaLearn","Big Data in Education 2.2 Diagnostic Metrics Part 1","","","","","https://www.youtube.com/watch?v=fGMFYTHhcHg&feature=youtu.be","","2015-06-24","2016-12-11 03:47:36","2016-12-11 03:47:36","2016-12-11 03:47:36","","","","","","","","","","","","","","","","","","","YouTube","","","<p>Notes</p> <ul> <li>Metrics for classifiers <ul> <li>Accuracy <ul> <li>One of the easiest measures of model goodness.&nbsp; Also called agreement, when measuring inter-rater reliability</li> <li>(# of agreements) / (total number of codes / assessments)</li> <li>General agreement that this is not a good metric <ul> <li>There is no assignment to categories</li> </ul> </li> <li>&nbsp;</li> </ul> </li> <li>Kappa <ul> <li>(Agreement – Expected Agreement) / (1 – Expected Agreement)</li> <li>Kappa = 0 <ul> <li>Agreement is at chance</li> </ul> </li> <li>Kappa = 1 <ul> <li>Agreement is perfect</li> </ul> </li> <li>Kappa = -1 <ul> <li>Agreement is a perfectly inverse</li> </ul> </li> <li>Kappa &gt; 1 <ul> <li>You messed up somewhere</li> </ul> </li> <li>Kappa &lt; 0 <ul> <li>Your model is worse than chance</li> </ul> </li> <li>0&lt;Kappa&lt;1 <ul> <li>In data mining .3-.5 is good</li> </ul> </li> <li>There is no standard for Kappa because it differs by category, organization, and type of data. <ul> <li>Comparing Kappa between datasets is difficult due to this.&nbsp; If you are going to compare they must be very similar.&nbsp;</li> </ul> </li> </ul> </li> </ul> </li> </ul>","","","","","","","","","","","","","","","","","","","","","","","","","517 seconds","","","","","","","","","","","","","","","","","","","","","","","","",""
"AGSP6PFG","videoRecording","2015","ColumbiaLearn","Big Data in Education 2.3  Diagnostic Metrics Part 2","","","","","https://www.youtube.com/watch?v=9PDwRdyb6Sw&feature=youtu.be","","2015-06-25","2016-12-11 03:47:39","2016-12-11 03:47:39","2016-12-11 03:47:39","","","","","","","","","","","","","","","","","","","YouTube","","","<p>Notes</p> <ul> <li>Different methods require different measures</li> <li>More metrics for classifiers <ul> <li>ROC: you are predicting something that has two values <ul> <li>Your prediction model outputs a probability or real value</li> <li>Four possibilities for classification thresholds <ul> <li>True positive: Both the model and data say it’s 1</li> <li>False positive: Data says 0, but model say 1</li> <li>True negative: Both data and model say 0.</li> <li>False negative: Data says 1, but the model says 0</li> </ul> </li> <li>ROC curve graphs 2 relations <ul> <li>First is on the x-axis&nbsp; <ul> <li>X-axis = Percent of false positives (versus true negatives) <ul> <li>False positives to the right</li> </ul> </li> </ul> </li> <li>Second is Y-axis <ul> <li>Y axis = Percent true positives (versus false negatives) <ul> <li>True positives going up</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li>A’ (A prime): The probability that if the model s given an example from each category, it will accurately identify which is which <ul> <li>A close relative of ROC.&nbsp;</li> <li>Closely approximates AUC (are under the ROC curve)</li> <li>More difficult to compute than kappa</li> <li>Only works for two categories, without complications</li> <li>A’ is almost always higher than Kappa because A’ takes confidence into account</li> </ul> </li> <li>Precision: (true positives) / (true positives + false positives) <ul> <li>The probability that a data point classified as true is actually true</li> </ul> </li> <li>Recall: (true positives) / (true positives + false negatives) <ul> <li>The probability that a data points that is actually true is classified as true</li> </ul> </li> </ul> </li> </ul>","","","","","","","","","","","","","","","","","","","","","","","","","723 seconds","","","","","","","","","","","","","","","","","","","","","","","","",""
"IQAREZMB","videoRecording","2015","ColumbiaLearn","Big Data in Education 2.4 Diagnostic Metrics: Correlation","","","","","https://www.youtube.com/watch?v=7r3hfJW1gz0&feature=youtu.be","","2015-07-21","2016-12-11 03:47:41","2016-12-11 03:47:41","2016-12-11 03:47:41","","","","","","","Big Data in Education 2.4 Diagnostic Metrics","","","","","","","","","","","","YouTube","","","<p>Notes</p> <ul> <li>Metrics for regressors <ul> <li>Linear correlation <ul> <li>When A’s values change, does B change in the same direction</li> <li>Assumes a linear relationship</li> <li>1 is a perfect correlation</li> <li>0 is no correlation</li> <li>-1 means perfectly negatively correlated</li> <li>Good correlation varies in fields</li> <li>In education 0.3 is good <ul> <li>Why is a low correlation okay in education?&nbsp; Lots and lots of factors contribute to just about any dependent measure.</li> </ul> </li> <li>&nbsp;</li> </ul> </li> <li>R squared: The correlation squared.&nbsp; <ul> <li>A measure of what percentage of variance in dependent measure is explained by a model</li> </ul> </li> <li>Man absolute deviation (MAD)/ Root Mean Squared Error (RMSE) <ul> <li>Both <ul> <li>Low RMSE/MAD is good</li> <li>High correlation is good</li> <li>Low RMSE/MAD, High Correlation = Good model <ul> <li>Model goes in the right direction, but is systematically biased</li> </ul> </li> <li>The opposite means bad model <ul> <li>Model values are in the right range, but the model does not capture relative change.&nbsp; This is common if there is not much variation in data.</li> </ul> </li> </ul> </li> <li>MAD <ul> <li>MAD is the average of the absolute value of the actual value minus the predicted value.</li> <li>Tells you the average amount to which the predictions deviate from the actual values.&nbsp; Very interpretable</li> </ul> </li> <li>RMSE <ul> <li>RMSE is the square root of the average of the actual value minus predicted value.</li> <li>Can be interpreted the same way (mostly) as MAD, but penalizes large deviation more than standard deviation</li> </ul> </li> </ul> </li> <li>Information Criteria <ul> <li>Bayesian Information Criteria (BIC) <ul> <li>Makes trade-offs between goodness of fit and flexibility of fit (number of parameters)</li> <li>Formula for linear regression <ul> <li>BIC = n log (1 – r^2) + p log n</li> <li>N us number of students, p is number of variables</li> </ul> </li> <li>Values over 0: worse than expected given number of variables</li> <li>Values under 0: Better than expected given number of variables</li> <li>Can be used to understand significance of difference between models</li> <li>Said to be statistically equivalent to k-fold cross-validation for optimal k</li> </ul> </li> <li>Akaike’s Information Criterion (AIC) <ul> <li>Alternative to BIC</li> <li>Makes slightly different trade-offs between goodness of fit and flexibility of fit (number of parameters).</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p><strong>&nbsp;</strong></p>","","","","","","","","","","","","","","","","","","","","","","","","","519 seconds","","","","","","","","","","","","","","","","","","","","","","","","",""
"AU9FU88V","videoRecording","2015","ColumbiaLearn","Big Data in Education 2.5 Cross-Validation and Over-Fitting","","","","","https://www.youtube.com/watch?v=1P34cxpEdKA&feature=youtu.be","","2015-06-29","2016-12-11 03:47:44","2016-12-11 03:47:44","2016-12-11 03:47:44","","","","","","","","","","","","","","","","","","","YouTube","","","<p>Notes</p> <ul> <li>Over-fitting: When you fit to the noise as well as the signal.&nbsp; Less good for new data.&nbsp; <ul> <li>To reduce over-fitting you can use simpler models (such as BIC and AIC)</li> <li>Less complex functions</li> <li>You cannot get rid of over-fitting, but you can alleviate it.</li> </ul> </li> <li>Cross validation: Cross-validation is a standard tool in analytics and is an important feature for helping you develop and fine-tune data mining models. You use cross-validation after you have created a mining structure and related mining models to ascertain the validity of the model. <ul> <li>Split data points into N equal-size groups</li> <li>Train on all group but one, test on last group</li> <li>For each possible combination</li> <li>Variants of cross-validation <ul> <li>Flat Cross-Validation <ul> <li>Each point has equal chance of being placed into each fold</li> <li>Stratified Cross-Validation <ul> <li>Biases fold selection so that some variable is equally represented in each fold</li> <li>The variable you’re trying to predict</li> <li>Or some variable that is thought to be an important context</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul>","","","","","","","","","","","","","","","","","","","","","","","","","419 seconds","","","","","","","","","","","","","","","","","","","","","","","","",""
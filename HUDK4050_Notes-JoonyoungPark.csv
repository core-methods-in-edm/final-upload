Key	Item Type	Publication Year	Author	Title	Publication Title	ISBN	ISSN	DOI	Url	Abstract Note	Date	Date Added	Date Modified	Access Date	Pages	Num Pages	Issue	Volume	Number Of Volumes	Journal Abbreviation	Short Title	Series	Series Number	Series Text	Series Title	Publisher	Place	Language	Rights	Type	Archive	Archive Location	Library Catalog	Call Number	Extra	Notes	File Attachments	Link Attachments	Manual Tags	Automatic Tags	Editor	Series Editor	Translator	Contributor	Attorney Agent	Book Author	Cast Member	Commenter	Composer	Cosponsor	Counsel	Interviewer	Producer	Recipient	Reviewed Author	Scriptwriter	Words By	Guest	Number	Edition	Running Time	Scale	Medium	Artwork Size	Filing Date	Application Number	Assignee	Issuing Authority	Country	Meeting Name	Conference Name	Court	References	Reporter	Legal Status	Priority Numbers	Programming Language	Version	System	Code	Code Number	Section	Session	Committee	History	Legislative BodyHH7FVM4V	journalArticle	2010	"Bowers, Alex J."	"Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis"	"Practical Assessment, Research & Evaluation"		1531-7714			"School personnel currently lack an effective method to pattern and visually interpret disaggregated achievement data collected on students as a means to help inform decision making. This study, through the examination of longitudinal K-12 teacher assigned grading histories for entire cohorts of students from a school district (n=188), demonstrates a novel application of hierarchical cluster analysis and pattern visualization in which all data points collected on every student in a cohort can be patterned, visualized and interpreted to aid in data driven decision making by teachers and administrators. Additionally, as a proof-of-concept study, overall schooling outcomes, such as student dropout or taking a college entrance exam, are identified from the data patterns and compared to past methods of dropout identification as one example of the usefulness of the method. Hierarchical cluster analysis correctly identified over 80% of the students who dropped out using the entire student grade history patterns from either K-12 or K-8. (Contains 5 figures.)"	2010-05	9/13/16 16:06	9/13/16 16:06	9/24/14 19:31			7	15			Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students							en					ERIC			"<ul> <li>Hierarchical cluster analysis and pattern visualization</li> <li>Clustergram: Visualization for every data points!</li> <li>Argue about the clustergram and actual implementations</li> <li>data mining usually focused on identifying and finding a pattern for the data</li> <li>After conducting Hierarchical cluster analysis,&nbsp; students who had low grades dropped out -&gt; which is obvious</li> <li>IT SHOWS but using grade for predicting drop out is not accurate because:overly concerned in core course failure<br />, other studies have been using other variables also to figure the drop rates but this study didn't<br />, and even if the past studies have focused on different factors, they did not compare across the grades</li> <li>Much more holistic view is needed</li> <li>3DM pre teachers data + elementary schools' data, not showing interesting results.</li> </ul>"		http://eric.ed.gov/?id=EJ933686		data; data analysis; Decision Making; Dropouts; Elementary School Students; Grades (Scholastic); Identification; MULTIVARIATE analysis; School Districts; Secondary School Students																																														UPSHGMV9	journalArticle	2014	"Grunspan, Daniel Z.; Wiggins, Benjamin L.; Goodreau, Steven M."	Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research	CBE-Life Sciences Education		", 1931-7913"	10.1187/cbe.13-08-0162	http://www.lifescied.org/content/13/2/167	"Social interactions between students are a major and underexplored part of undergraduate education. Understanding how learning relationships form in undergraduate classrooms, as well as the impacts these relationships have on learning outcomes, can inform educators in unique ways and improve educational reform. Social network analysis (SNA) provides the necessary tool kit for investigating questions involving relational data. We introduce basic concepts in SNA, along with methods for data collection, data processing, and data analysis, using a previously collected example study on an undergraduate biology classroom as a tutorial. We conduct descriptive analyses of the structure of the network of costudying relationships. We explore generative processes that create observed study networks between students and also test for an association between network position and success on exams. We also cover practical issues, such as the unique aspects of human subjects review for network studies. Our aims are to convince readers that using SNA in classroom environments allows rich and informative analyses to take place and to provide some initial tools for doing so, in the process inspiring future educational studies incorporating relational data."	6/20/14	9/13/16 16:06	9/13/16 16:06	8/20/14 20:21	167-178		2	13		CBE Life Sci Educ	Understanding Classrooms through Social Network Analysis							en					www.lifescied.org			"<p>Which would yield better SNA result and better achievement for final projects: Group defined by professor or group made by students? I feel like group defined by students would yield more extreme performances while students who were grouped by professor would be showing more average performances between group.</p> <p>Actor=nodes</p> <p>Unipartite= one mode - one type of actor/ bipartite=twomode - actor in the group</p> <p>ties between actor/ bidirectional = undirected</p> <p>density= how much network is connected between each other more the dense</p> <p>how many ties/who is connected with whom?</p> <p>homophilly= connected with similar interest with disproponately (based from social selection - finding for A student and social influence - studying with A student)</p> <p>triad and transitivity</p> <p>Centerality(degree,closeness,betweeness, eigenvector)</p> <p>Degree centrality - number of connectionsnot significant result turned out but it will be found out with different methods in the future</p>"		http://www.lifescied.org/content/13/2/167	Week 2																																															JXPD425U	blogPost	2014	"Young, Jeffrey R."	Why Students Should Own Their Educational Data	The Chronicle of Higher Education Blogs: Wired Campus				http://chronicle.com/blogs/wiredcampus/why-students-should-own-their-educational-data/54329		8/21/14	9/13/16 16:06	9/13/16 16:06	8/23/14 21:32																						"<p>&nbsp;Especially in the context like mooc, it becomes meaningless to find the average learner because there are so many different level students coming into the program and it would not be accurate enough to average them. To some it would be too easy, and too others it would be too hard. But since Mooc has to show their result, at their initial stages, they might have to use the averaged data (which would mean nothing).</p>"		http://chronicle.com/blogs/wiredcampus/why-students-should-own-their-educational-data/54329																																																P9N8HC2I	journalArticle	1994	"Corbett, Albert T.; Anderson, John R."	Knowledge tracing: Modeling the acquisition of procedural knowledge	User Modeling and User-Adapted Interaction		"0924-1868, 1573-1391"	10.1007/BF01099821	http://link.springer.com.ezp-prod1.hul.harvard.edu/article/10.1007/BF01099821	"This paper describes an effort to model students' changing knowledge state during skill acquisition. Students in this research are learning to write short programs with the ACT Programming Tutor (APT). APT is constructed around a production rule cognitive model of programming knowledge, called theideal student model. This model allows the tutor to solve exercises along with the student and provide assistance as necessary. As the student works, the tutor also maintains an estimate of the probability that the student has learned each of the rules in the ideal model, in a process calledknowledge tracing. The tutor presents an individualized sequence of exercises to the student based on these probability estimates until the student has ‘mastered’ each rule. The programming tutor, cognitive model and learning and performance assumptions are described. A series of studies is reviewed that examine the empirical validity of knowledge tracing and has led to modifications in the process. Currently the model is quite successful in predicting test performance. Further modifications in the modeling process are discussed that may improve performance levels."	12/1/94	9/13/16 16:06	9/13/16 16:06	4/21/13 21:21	253-278		4	4		User Model User-Adap Inter	Knowledge tracing							en					link.springer.com.ezp-prod1.hul.harvard.edu			"<p>How to achieve mastery learning</p> <p>1) domain knowledge is analyzed and stored in the hierarhical way</p> <p>2)Learning experience are requisite for tackling the higher concept</p> <p>cognitive model of skill acqusitioin, goal of mastery of learning in mind</p> <ol> <li>The ACT programming tutor</li> <li>The cognitive model</li> <li>Knowledge tracing and mastery learning</li> <li>Empirical evaluation of Knowledge tracing</li> <li>Future directions</li> </ol>"				"Education (general); empirical validity; individual differences; intelligent tutoring systems; Learning; Management of Computing and Information Systems; mastery learning; Multimedia Information Systems; procedural knowledge; Psychology, general; student modeling; User Interfaces and Human Computer Interaction"																																														ZM5MZSWN	conferencePaper	2012	"Siemens, George; Baker, Ryan S. J. d."	Learning Analytics and Educational Data Mining: Towards Communication and Collaboration	Proceedings of the 2Nd International Conference on Learning Analytics and Knowledge	978-1-4503-1111-3		10.1145/2330601.2330661	http://doi.acm.org/10.1145/2330601.2330661	"Growing interest in data and analytics in education, teaching, and learning raises the priority for increased, high-quality research into the models, methods, technologies, and impact of analytics. Two research communities -- Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK) have developed separately to address this need. This paper argues for increased and formal communication and collaboration between these communities in order to share research, methods, and tools for data mining and analysis in the service of developing both LAK and EDM fields."	2012	9/13/16 16:06	9/13/16 16:06	1/16/15 3:15	252–254						Learning Analytics and Educational Data Mining					ACM	"New York, NY, USA"						ACM Digital Library			"<p>After reading this article, I felt like LAK should be implemented more in children's learning (until elementary school) and EDM model should be implemented in adolescents and adult learning. I felt like at least people at their adolescent age can define what they know and what they do not know, so they might be better at utilizing the resources rather than children in their elementary schools where still fundamental learning has to be done.</p>; <p>difference between LAK and EDM</p> <p>EDM=rooted in tech field, LA=ed field</p> <p>EDM= Automation/tech driven, LA= using tech as a tool to enhance human judgement</p> <p>methodological difference</p> <p>&nbsp;EDM = machine learning LA=text&amp;SNA</p> <p>EDM =individual LA= holistic</p> <p>Challenge of intergrating the tech and ed</p>"				Collaboration; educational data mining; learning analytics and knowledge																																														8UQJXKBN	journalArticle	2008	"Baker, Ryan S. J. d; Corbett, Albert T.; Roll, Ido; Koedinger, Kenneth R."	Developing a generalizable detector of when students game the system	User Modeling and User-Adapted Interaction		"0924-1868, 1573-1391"	10.1007/s11257-007-9045-6	http://link.springer.com.ezp-prod1.hul.harvard.edu/article/10.1007/s11257-007-9045-6	"Some students, when working in interactive learning environments, attempt to “game the system”, attempting to succeed in the environment by exploiting properties of the system rather than by learning the material and trying to use that knowledge to answer correctly. In this paper, we present a system that can accurately detect whether a student is gaming the system, within a Cognitive Tutor mathematics curricula. Our detector also distinguishes between two distinct types of gaming which are associated with different learning outcomes. We explore this detector’s generalizability, and find that it transfers successfully to both new students and new tutor lessons."	8/1/08	9/13/16 16:06	9/13/16 16:06	1/16/15 16:33	287-314		3	18		User Model User-Adap Inter								en					link.springer.com.ezp-prod1.hul.harvard.edu			"<p>Students who are gaining the system: students who do not work hard to gain information from the course material itself and just trying to gain it by ""gaming the system"" searching through other aspects of the tutorial, quickly asking for help, answering numbers quickly</p> <p>-&gt; System can detect this!</p> <p>accurately detects which students game the system</p> <p>gaming behavior does not happen abruptly: when bored or hard - possibility of creating learning intervention</p> <p>expands our knowledge about the behavioral constructs of gaming the system</p> <p>can generalize between the context</p>"		http://link.springer.com.ezp-prod1.hul.harvard.edu/article/10.1007/s11257-007-9045-6		Behavior detection; Cognitive tutors; Education (general); Gaming the system; Generalizable models; Interactive learning environments; Latent response models; Machine learning; Management of Computing and Information Systems; Multimedia Information Systems; student modeling; User Interfaces and Human Computer Interaction																																														GN9JQVJW	book	2015	"Zheng, Alice"	Evaluating Machine Learning Models					http://www.oreilly.com/data/free/evaluating-machine-learning-models.csp?intcmp=il-data-free-lp-lgen_free_reports_page	"Data science today is a lot like the Wild West: there’s endless opportunity and excitement, but also a lot of chaos and confusion. If you’re new to data science and applied machine learning, evaluating a machine-learning model can seem pretty overwhelming..."	2015-09	9/13/16 16:06	9/13/16 16:06	12/15/15 18:26												O'Reily Media	"Sebastopol, CA"									"<p>Evaluation metrics</p> <p>There are different metrics for the tasks of classification, regression, ranking, clustering, topic modeling, etc.</p> <p>Classification, regression, and ranking - example of supervised learning</p> <p>Classification metrics</p> <p>&nbsp;&nbsp;&nbsp; Accuracy</p> <p>accuracy = # of correct prediction/ # total data points</p> <p>&nbsp;&nbsp;&nbsp; Confusion Matrix</p> <p>False postivie: when doctor diagnose cancer which individual actually do not have</p> <p>False negative: call for not having a cancer but they actually have one</p> <p>&nbsp;&nbsp;&nbsp; Per-Class Accuracy</p> <p>average of accuracy for each class</p> <p>if classes have extremely different result inside -&gt; problem</p> <p>&nbsp;&nbsp;&nbsp; Log-loss</p> <p>If the data set is not binary number data, we can use the log-loss. This is gauge of confidence/ decision boundary: 0.5/ information-theoretic measure to gauge the extra noise</p> <p>&nbsp;&nbsp;&nbsp; AUC</p> <p>area under the curve/Curve is ROC (Receiver operating characteristic curve) = sensitivity of the classifier by plotting the rate of true positives to the rate of false positive/ how many correct positive classification can be grained as allow more false positive</p> <p>Ranking metrics</p> <p>Binary classification/ used for Internet search &amp; personalized recommendation</p> <p>&nbsp;&nbsp;&nbsp; Precision-recall</p> <p>Also popular classification tasks</p> <p>Actually two different metric but grouped into one Correct answers comes from overlap of Returned by the ranker/ classifier and Relavant</p> <p>&nbsp;&nbsp;&nbsp; Precision recall curve and the F1 score</p> <p>if either precision or recall is small then F1 score is small</p> <p>&nbsp;&nbsp;&nbsp; NDGG</p> <p>making the top research result meaningful! Normailized discounted cumulative gain</p> <p>Regression metrics</p> <p>Predict numeric scores (predict stock, predict user's rating for the item)</p> <p>&nbsp;&nbsp;&nbsp; RMSE</p> <p>root mean square error</p> <p>&nbsp;&nbsp;&nbsp; Quantiles of errors</p> <p>catches the outliers</p> <p>&nbsp;&nbsp;&nbsp; Precision- recall curve and F1 Score</p> <p>&nbsp;&nbsp;&nbsp; Almost correct predictions</p> <p>in the range?!?!</p> <p>Caution: The difference between training metrics and evaluation metrics</p> <p>Avoid as much as possible/ do not make them work they are not programmed to</p> <p>Caution: Skewed Datasets - Imbalanced classes, outliers, and rare data</p> <p>imbalanced data, data skew, outlier -&gt; conversation with pros maybe?</p> <p>&nbsp;&nbsp;</p>"		http://www.oreilly.com/data/free/evaluating-machine-learning-models.csp?intcmp=il-data-free-lp-lgen_free_reports_page																																																9GG36PBC	blogPost	2015	"Leong, B; Polonetsky, J"	Why Opting Out of Student Data Collection Isn’t the Solution	EdSurge				https://www.edsurge.com/news/2015-03-16-why-opting-out-of-student-data-collection-isn-t-the-solution	"In every privacy debate across every industry, the same questions arise about the rights of individuals to “opt-out” of their data being collected or used. So it should come as no surprise that the “when” and “how” of parent and student opt-outs of education data collection or use has become a robust"	3/16/15	9/13/16 16:06	9/13/16 16:06	1/16/16 16:31																						"<p>First of all, it is great that California took the initiative to</p>"		https://www.edsurge.com/news/2015-03-16-why-opting-out-of-student-data-collection-isn-t-the-solution																																																ARS28RVG	videoRecording	2015	Educause	Why Is Measuring Learning So Difficult?					https://www.youtube.com/watch?v=_iv8A1pHNYA	Several higher education learning and assessment professionals discuss the difficulties of measuring learning.	8/17/15	9/13/16 16:06	9/13/16 16:06	1/17/16 18:50																			YouTube			"<p>Don't know where a student is starting from</p> <p>cant measure all the ways that people learn</p> <p>based on proxies, but proxies change based on context not just individual</p> <p>we have to simplify but may throw away the signal and keep the noise</p> <p>&nbsp;</p>; <p>In order to get the pure data we to much define and restrict the setting to get the data which could not be generalizable</p> <p>defining learning experience is difficult (what we are trying to measure) ; even defining what we are measuring can be difficult.</p> <p>learning is self experience and it needs to be engaged by individual themselves; motivation is the key</p> <p>competency before learning experience can be different; especially in MOOC settings</p> <p>learning as achievement or learning as a self efficacy</p> <p>&nbsp;</p>"				Assessment; Education; educational assessment; EDUCAUSE; Higher Education; learners; Learning; Teaching and learning																					470 seconds																									QAIHSVGC	webpage	2016	"Weinersmith, Zach"	Saturday Morning Breakfast Cereal					http://www.smbc-comics.com/index.php?id=3978		1/5/16	9/13/16 16:06	9/13/16 16:06	1/18/16 18:17																						"<p>The SMBC comic reminded me of what will happen if we force our students to learn how to code and its’ consequences. But aren’t we already living in a world like this? We live in a world assuming everything is run by accurate, but we are also living in a society where sending a divorce therapist commercial email on one’s wedding anniversary based on the “big data.”</p> <p>&nbsp;</p>"		http://www.smbc-comics.com/index.php?id=3978																																																A9Z2DGUR	conferencePaper	2014	"Clow, Doug"	Data wranglers: human interpreters to help close the feedback loop	Proceedings of the Fourth International Conference on Learning Analytics And Knowledge						2014	9/13/16 16:06	9/13/16 16:06		49–53											ACM										"<p>Wrangle means to attempt to deal with or understand something contend or struggle.</p> <p>(Contend means to strive in opposition or against difficulties (such as race,competition, debate))</p> <p>Data wranglers should be actively engage in data analyzing&nbsp; to help students who are taking the course on real time, not afterwards. Like the ""New classroom"" we visited at the start of this month!</p> <p>The article keep mentioned about substantial organizational change with real time information input from data wranglers, but now, it would be little bit hard for this to happen because many people do not know the importance of Data Wrangler! Many possible job opportunities out there?!?!</p>"																																																		EHIHJ586	magazineArticle	2015	"Kucirkova, Natalia; FitzGerald, Elizabeth"	Zuckerberg is ploughing billions into 'personalised learning' – why?	The Conversation				http://theconversation.com/zuckerberg-is-ploughing-billions-into-personalised-learning-why-51940	"Zuckerburg wants to plough billions into personalised learning, but his way may not be the right way."	12/9/15	9/13/16 16:06	9/13/16 16:06	1/18/16 19:14																						"<p>I think if we were to implement the personalized learning through technology, we should redefine the role of school and teachers at school. It is great that all of the children gets the personalized learning, but I think we should consider what would be the end point of implementing different learning materials to students. One of the main role of the school is to teach and make students understand until the certain level of achievement not all students to do exceedingly well in every subject. If this personalized learning is implemented, teachers have to be prepared for all level of experties in his/her subject. This would not replacing human work unless there is complex algorithm to pinpoint the student's weakness.</p>"		https://theconversation.com/zuckerberg-is-ploughing-billions-into-personalised-learning-why-51940																																																QAK2RGH6	videoRecording	2015	Georgia Tech	Feature Selection					https://www.youtube.com/watch?v=8CpRLplmdqE		2/23/15	9/13/16 16:06	9/13/16 16:06	1/18/16 19:18												Youtube										"<p>Interpretability and insight of feature - thinking about the user</p> <p>curse of dimensionality&nbsp; more feature, more contents making every one's life easier</p> <p>conclusion: make some of the data less/Feature less and data more</p> <p>&nbsp;</p>"		https://www.youtube.com/watch?v=8CpRLplmdqE															Udacity								3:13																									ZQRA7ET6	bookSection	2016	"Hanneman, R.A.; Riddle, M."	Chapter 1: Social Network Data	Introduction to Social Network Methods				http://faculty.ucr.edu/~hanneman/nettext/C1_Social_Network_Data.html		1/18/16	9/13/16 16:06	9/13/16 16:06	1/18/16 20:17																						"<p>Social network data</p> <p>Introduction: What is different about social network data?</p> <ul> <li>In the network data the columm can be relationship between actors.</li> <li>See how actors are located or embedded in the overall network</li> <li>densitiy</li> <li>not a conventional data - focuses on relationship</li> <li>nodes (or actors) edges (or relations)</li> </ul> <p>Nodes</p> <ul> <li>Sample elements are not independent</li> </ul> <p>&nbsp;&nbsp;&nbsp; Populations, samples, and boundaries</p> <ul> <li>Rather than drawing a population for a survey use more demographic stuff, do not get rid of participants</li> </ul> <p>&nbsp;&nbsp;&nbsp; Modality and level analysis</p> <ul> <li>good for multiple level analysis and multi modal data structure, but also no in depth take away message</li> </ul> <p>Relations</p> <ul> <li>when we are analyzing the data, there are not random people, they were previously some what related.</li> </ul> <p>&nbsp;&nbsp;&nbsp; Sampling ties</p> <ul> <li>Full network methods</li> <li>Snowball methods</li> <li>Egocentric networks (with alter connections/ Ego only)</li> </ul> <p>&nbsp;&nbsp;&nbsp; Multiple relations</p> <ul> <li>conceptual approaches/ how to take a class</li> </ul> <p>Scales of measurement</p> <ul> <li>Binary measures of relations:</li> <li>Multipe category nominal measures of relations</li> <li>Grouped ordinal measures of relations</li> <li>Full rank ordinal measure of relations</li> <li>Interval measures of relations</li> </ul> <p>A note on statistics and social network data</p> <ul> <li>&nbsp;&nbsp;&nbsp; not a social science! more mathmatical</li> </ul>"		http://faculty.ucr.edu/~hanneman/nettext/C1_Social_Network_Data.html																																																IWXICZM8	webpage	2014	"Groelmund, Garrett"	RStudio Cheat Sheets	RStudio				https://www.rstudio.com/resources/cheatsheets/		8/1/14	9/13/16 16:06	9/13/16 16:06	1/19/16 21:17																								http://shiny.rstudio.com/articles/rm-cheatsheet.html																																																VUQED3Z6	conferencePaper	2013	"san Pedro, Maria Ofelia; Baker, Ryan; Bowers, Alex; Heffernan, Neil"	Predicting college enrollment from student interaction with an intelligent tutoring system in middle school	Educational Data Mining 2013						2013	9/13/16 16:06	9/13/16 16:06																							"<p>Having a higher aiming goal starting from the middle school help students to achieve higher (need to care for their own grades in order to go to the college)</p> <p>The researchers used ASSISTment system 04~05, 06~07</p> <p>(seems like ASSISTment used the theory of Vygotsky, to scaffold!)</p> <p>Student knowledge estimated by Bayesian Knowledge Tracing</p> <p>the program could predict students' college enrollment 68.6% of the time (boredom, confusion, and slip/careness are he significant determinent in college enrollment</p> <p>Possibility of interaction log?</p>"																																																		M369Z5EF	journalArticle	2012	"Greller, Wolfgang; Drachsler, Hendrik"	Translating Learning into Numbers: A Generic Framework for Learning Analytics	Journal of Educational Technology & Society		1176-3647		http://www.jstor.org/stable/jeductechsoci.15.3.42	"ABSTRACT With the increase in available educational data, it is expected that Learning Analytics will become a powerful means to inform and support learners, teachers and their institutions in better understanding and predicting personal learning needs and performance. However, the processes and requirements behind the beneficial application of Learning and Knowledge Analytics as well as the consequences for learning and teaching are still far from being understood. In this paper, we explore the key dimensions of Learning Analytics (LA), the critical problem zones, and some potential dangers to the beneficial exploitation of educational data. We propose and discuss a generic design framework that can act as a useful guide for setting up Learning Analytics services in support of educational practice and learner guidance, in quality assurance, curriculum development, and in improving teacher effectiveness and efficiency. Furthermore, the presented article intends to inform about soft barriers and limitations of Learning Analytics. We identify the required skills and competences that make meaningful use of Learning Analytics data possible to overcome gaps in interpretation literacy among educational stakeholders. We also discuss privacy and ethical issues and suggest ways in which these issues can be addressed through policy guidelines and best practice examples."	2012	9/13/16 16:06	9/13/16 16:06	9/3/16 18:55	42-57		3	15		Journal of Educational Technology & Society	Translating Learning into Numbers												JSTOR			<p>It is a how to for Learning Analytics</p> <p>6 dimensions to do Learning Analytics correctly</p> <p>Stake holders</p> <ul> <li>Institution</li> <li>Teachers</li> <li>Learners</li> <li>Other</li> </ul> <p>Objective</p> <ul> <li>Reflection</li> <li>Prediction</li> </ul> <p>Data</p> <ul> <li>Open</li> <li>Protected</li> </ul> <p>Instruments</p> <ul> <li>Technology</li> <li>Algorithm</li> <li>Theories</li> <li>Other</li> </ul> <p>External Limitations</p> <ul> <li>Conventions</li> <li>Norm</li> </ul> <p>Internal limitations</p> <ul> <li>Competence</li> <li>Acceptance</li> </ul> <p>TEL: Technology Enhanced Learning</p> <p>We should be aware that not all students put their full effort to TEL learning program which might distort the data analysis. Or do they turn out to mean something?</p> <p>&nbsp;</p> <p>&nbsp;</p>																																																		UPNATQ2U	bookSection	2006	"Kay, Judy; Maisonneuve, Nicolas; Yacef, Kalina; Reimann, Peter"	The Big Five and Visualisations of Team Work Activity	Intelligent Tutoring Systems	978-3-540-35159-7 978-3-540-35160-3			http://link.springer.com/chapter/10.1007/11774303_20	"We have created a set of novel visualisations of group activity: they mirror activity of individuals and their interactions, based upon readily available authentic data. We evaluated these visualisations in the context of a semester long software development project course. We give a theoretical analysis of the design of our visualizations using the framework from the “Big 5” theory of team work as well as a qualitative study of the visualisations and the students’ reflective reports. We conclude that these visualisations provide a powerful and valuable mirroring role with potential, when well used, to help groups learn to improve their effectiveness."	6/26/06	9/13/16 16:06	9/13/16 16:06	9/3/16 19:10	197-206											Springer Berlin Heidelberg		en	©2006 Springer-Verlag Berlin Heidelberg				link.springer.com			"<p>Computer supported collaborative learning (CSCL)/ team work do not visualized in the online learning setting</p> <p>Big five components of team work</p> <ul> <li>Team leadership</li> </ul> <p>leader assigns how many ticket to use and people interact with ticket activity</p> <p>Facilitate teem problem solving</p> <p>provide performance expectations and acceptable interaction patterns</p> <p>Synchronize and combine individual team member contributions see and evaluate information that affects team functioning</p> <ul> <li>Mutual performance monitoring</li> </ul> <p>Measured with interaction networks</p> <p>low level of interaciton, low level of monitor</p> <p>Identifying mistakes and lapses in other team members' actions</p> <ul> <li>Back up behavior</li> </ul> <p>Shift workload in the high pressure settings</p> <p>Recognition of a workload distribution problem in the team</p> <p>shifting work to under utilized members</p> <ul> <li>Adaptability</li> </ul> <p>It does not mean if it is not there the team is not successful</p> <p>Identify cues of change, assign meaning to it, develop a new plan to deal with it.</p> <ul> <li>Team orientation</li> </ul> <p>Degree of involvment, completion of milestone</p> <p>Increase task involvment, information sharing, strategising and goal settings</p> <p>Coordinating mechanisms</p> <ul> <li>Shared mental models</li> <li>Mutual trust</li> <li>Closed loop communications</li> </ul> <p>#feedback</p> <p>Visualization tools</p> <ul> <li>Activity radar</li> <li>Interaction Network</li> <li>Wattle tree</li> </ul>"		https://link.springer.com/chapter/10.1007/11774303_20		Artificial Intelligence (incl. Robotics); Computers and Education; Information Systems Applications (incl. Internet); Multimedia Information Systems; User Interfaces and Human Computer Interaction	"Ikeda, Mitsuru; Ashley, Kevin D.; Chan, Tak-Wai"																																													X839V4H2	journalArticle	2015	"Konstan, Joseph A.; Walker, J. D.; Brooks, D. Christopher; Brown, Keith; Ekstrand, Michael D."	Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC	ACM Trans. Comput.-Hum. Interact.		1073-0516	10.1145/2728171	http://doi.acm.org/10.1145/2728171		2015-04	9/13/16 16:06	9/13/16 16:06	9/3/16 20:38	10:1–10:23		2	22			Teaching Recommender Systems at Large Scale												ACM Digital Library			"<ul> <li>Measurement, performance, Massively open online course, learning assessment</li> <li>Research goal summary</li> <li>Do students learn with Mooc? Do students interact with Mooc? role of recommending system in learning&nbsp; and learner experience? Will the students remember what they have learned from mooc five months later?</li> <li>Results:</li> <li>Strong will predict if the student will end the course or not/ other won't matter that much. Students learned through mooc and benefitted from mooc.. We also might conclude based on the teacher-student physical class might be that much helpful if the mooc quality is good enough. Programming students gain more knowldege (you know more, you learn more). Effort to learn only predict the actual gain of knowledge. Normalized knowledge gain is hard to predict! Need to know students' starting point and end point!</li> <li>Motivation, easy to access, need to hide some of the obvious purpose for the experiment</li> </ul>"				learning assessment; Massively Online Open Course (MOOC)																																														GKQK5NA4	bookSection	2013	"Desmarais, Michel C.; Naceur, Rhouma"	A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices	Artificial Intelligence in Education	978-3-642-39111-8 978-3-642-39112-5			http://link.springer.com/chapter/10.1007/978-3-642-39112-5_45	"Uncovering the right skills behind question items is a difficult task. It requires a thorough understanding of the subject matter and of the cognitive factors that determine student performance. The skills definition, and the mapping of item to skills, require the involvement of experts. We investigate means to assist experts for this task by using a data driven, matrix factorization approach. The two mappings of items to skills, the expert on one side and the matrix factorization on the other, are compared in terms of discrepancies, and in terms of their performance when used in a linear model of skills assessment and item outcome prediction. Visual analysis shows a relatively similar pattern between the expert and the factorized mappings, although differences arise. The prediction comparison shows the factorization approach performs slightly better than the original expert Q-matrix, giving supporting evidence to the belief that the factorization mapping is valid. Implications for the use of the factorization to design better item to skills mapping are discussed."	7/9/13	9/13/16 16:06	9/13/16 16:06	9/3/16 20:44	441-450											Springer Berlin Heidelberg		en	©2013 Springer-Verlag Berlin Heidelberg				link.springer.com			"<p>Mapping items to the skill is really hard (as we already know)</p> <p>Using ALS (Alternate least-square Factorization), compare between expert defined Q matrix and a factor Q matirx</p> <p>2 or 3 changes in initial matrix lead to toward change in total ALS system</p> <p>(The article was hard to understand (T.T))</p>"		https://link.springer.com/chapter/10.1007/978-3-642-39112-5_45		alternating least squares matrix factorization; Artificial Intelligence (incl. Robotics); Cognitive modeling; Computers and Education; Educational Technology; Information Systems Applications (incl. Internet); latent skills; Pedagogic Psychology; skills assessment; Student models; User Interfaces and Human Computer Interaction	"Lane, H. Chad; Yacef, Kalina; Mostow, Jack; Pavlik, Philip"																																													7ICJGX2R	book	2015	"Matsuda, Noboru; Furukawa, Tadanobu; Bier, Norman; Faloutsos, Christos"	Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement					http://eric.ed.gov/?id=ED560513	"How can we automatically determine which skills must be mastered for the successful completion of an online course? Large-scale online courses (e.g., MOOCs) often contain a broad range of contents frequently intended to be a semester's worth of materials; this breadth often makes it difficult to articulate an accurate set of skills and knowledge (i.e., a skill model, or the QMatrix). We have developed an innovative method to discover skill models from the data of online courses. Our method assumes that online courses have a pre-defined skill map for which skills are associated with formative assessment items embedded throughout the online course. Our method carefully exploits correlations between various parts of student performance, as well as in the text of assessment items, to build a superior statistical model that even outperforms human experts. To evaluate our method, we compare our method with existing methods (LFA) and human engineered skill models on three Open Learning Initiative (OLI) courses at Carnegie Mellon University. The results show that (1) our method outperforms human-engineered skill models, (2) skill models discovered by our method are interpretable, and (3) our method is remarkably faster than existing methods. These results suggest that our method provides a significant contribution to the evidence-based, iterative refinement of online courses with a promising scalability. [For complete proceedings, see ED560503.]"	2015-06	9/13/16 16:06	9/13/16 16:06	9/3/16 20:48							Machine Beats Experts					International Educational Data Mining Society		en					ERIC			"<p>Online course programming: Who is better? Computer or human?</p> <p>To test: LFA (Learning factor analysis) vs human engineered model vs eEpiphany</p> <p>eEpiphany was the best even when using bag of words (F matrix for collected items)</p> <p>eEpiphany seems to be very effective tool to revise and give students information which course to take, but is this is only the tool that makes helpful for advising course content?</p>"		http://eric.ed.gov/?id=ED560513		Automation; Comparative Analysis; Correlation; data; Formative Evaluation; models; Online Courses; Skills																																														83JIGF4U	conferencePaper	2008	"Cortez, Paulo; Silva, Alice Maria Gonçalves"	Using data mining to predict secondary school student performance	Proceedings of 5th Annual Future Business Technology Conference	978-90-77381-39-7			http://repositorium.sdum.uminho.pt/handle/1822/8024	"Although the educational level of the Portuguese population has improved in the last decades, the statistics keep Portugal at Europe’s tail end due to its high student failure rates. In particular, lack of success in the core classes of Mathematics and the Portuguese language is extremely serious. On the other hand, the fields of Business Intelligence (BI)/Data Mining (DM), which aim at extracting high-level knowledge from raw data, offer interesting automated tools that can aid the education domain. The present work intends to approach student achievement in secondary education using BI/DM techniques. Recent real-world data (e.g. student grades, demographic, social and school related features) was collected by using school reports and questionnaires. The two core classes (i.e. Mathematics and Portuguese) were modeled under binary/five-level classification and regression tasks. Also, four DM models (i.e. Decision Trees, Random Forest, Neural Networks and Support Vector Machines) and three input selections (e.g. with and without previous grades) were tested. The results show that a good predictive accuracy can be achieved, provided that the first and/or second school period grades are available. Although student achievement is highly influenced by past evaluations, an explanatory analysis has shown that there are also other relevant features (e.g. number of absences, parent’s job and education, alcohol consumption). As a direct outcome of this research, more efficient student prediction tools can be be developed, improving the quality of education and enhancing school resource management."	2008-04	9/13/16 16:06	9/13/16 16:06	9/4/16 1:23												EUROSIS	"Porto, Spain"	eng	openAccess				repositorium.sdum.uminho.pt			"<p>Portuguese have been developed for their education, but still at the tail of the Europe's achievement.</p> <p>Situation for students achieving level for math and portuguese is serious analyze students' data with Business Intelligence and data mining results</p> <p>Goal: identify students achievement and find key variables, what makes students pass or fail</p> <p>Used classification and regression (Binary classifcation, 5 level classification, and regression) and RMiner package in R (Decision trees, random forests, Neural Networks, and support vector machines + With without past grades</p> <p>Predicted well (failures, G1 grade, G2 grade were the highest predictors)</p>"		http://repositorium.sdum.uminho.pt/handle/1822/8024																																	5th Annual Future Business Technology Conference															NSVPSAKH	book	2014	"Baker, R"	Big Data in Education							2014	9/13/16 16:06	9/13/16 16:06														"New York, NY"									"<p>1.1 Introduction</p> <p>Explore big data in education</p> <p>Called educational data mining or learning analytics</p> <p>Joint goal of exlploring the big data now availabe on learners and learning</p> <p>To promote new scientific discoveries and to advance learning sciences</p> <p>To promote better assessmetns of learners along multiple dimensions</p> <p>to promote better realtime support for learners</p> <p>A few words for data miners</p> <p>may find some classic algorithms aren't well represented like neural networks - they haven't been all that heavily used in EDM and one reason is that overfitting is a plague in the highly context based and not that big data set we use</p> <p>It is big enough but not in the level of google big</p> <p>Types of EDM/LA method</p> <p>Prediction</p> <p>Develop a model which can infer a single aspect of the data (predicted variables) from some combination of other aspects of the data (predictor variables)</p> <p>Structure discovery</p> <p>Find structure and patterns in the data that emerge naturally</p> <p>Relationship mining</p> <p>Discover relationships between variables in a dataset with many variables</p> <p>Discovery with models</p> <p>Preexisting model/ applied to data and used as a component in another analysis</p> <p>Why not popular until now?</p> <p>not enough data hard to scale</p> <p>now.. mooc!</p> <p>PSLC Datashop - Actions: entering an equation, manipulating a vector, typing a phrase, requesting help</p> <p>-responses: error feedback, strategic hints</p> <p>-Annotations: correctness, time, skill/ concept</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p>; <p>1.3 Classifiers, Part 1</p> <p>Classification</p> <p>there is something you want to predict (""the label"")</p> <p>the thing you want to predict is categorical</p> <p>-answer is one set of categories not a number</p> <p>-like 0,1</p> <p>-help requst/ worked example requests/ attempt to solve</p> <p>-will dropout/ won't drop out</p> <p>-will enroll in mooc ABCDEFE</p> <p>Classification: Associated with each label are a set of ""features"" which may be you can use to predict the label</p> <p>the basic idea of a classifier is to determine which features, in which combination can predict the label</p> <p>Domain specificity</p> <p>Specific algorithms work better for specific domains and problems</p> <p>step regression: not stepwise regression, used for binary classification</p> <p>fits linear regression fuction- with an arbitrary cut off/ selects parapmeters, assigns a weight to each parameter, computes a numerical value</p> <p>not prefered by statisticians but it is okay in EDM</p> <p>Logistic regression</p> <p>Given a specific set of values of predictor variables</p> <p>Fits logistic fuction to data to find out the frequency/ odds of a specific value of the dependent variable</p> <p>good for cases where changes in value of predictor variables have predictable effects on probability of predicted variable class</p> <p>Logistic and step regression are good when interactions are not particularly common</p> <p>can be given interaction effects through automated feature distillation</p> <p>Instead, use decision tree! can be adjusted to split based on more or less evidence, to prune based on more or less predictive power</p>; <p>1.4 Classifiers, Part 2</p> <p>Classifiers</p> <p>Decision rules- set of if -then rules which you check in order (if, else if )</p> <p>Many algorithms</p> <p>Differences are in terms of how rules are generated and selected/ most popular subcatergory repeatedly&nbsp; creates decision trees and distills best rules</p> <p>Generating rules from decision tree</p> <p>1. Create decision tree</p> <p>2. If there is at least one path that is worth keeping go to 3 else go to 6</p> <p>3. Take the best single path from root to leaf and make that path a rule</p> <p>4. Remove all datapoints classified by that rule from data step</p> <p>5. Go to step 1</p> <p>6. Take all remaining datapoints</p> <p>7. find the most common value for those datapoints</p> <p>8. make an ""otherwise"" rule using that</p> <p>Relatively conservative - leads to simpler model than most decision trees</p> <p>Very interpretive model</p> <p>K*</p> <p>Predicts a data point from neighboring data points - weights points more strongly if they are near by</p> <p>good when data is very divergent, might be the only tools to use in some cases (detecting emotions from the log file)</p> <p>but you need whole data set to perform this method</p> <p>bagged stumps - lots of trees with only the first feature/relatively conservative close variant is random forest</p> <p>~~~so far classifiers are conservative; find simple models, don't over fit/ these algorithm more suitable for educational data mining, which means educational data has a lot of noise~~~</p> <p>SVM: support vector machines</p> <p>Conducts dimensionality reduction on data space and then fits hyper plane which splits classes</p> <p>creates very sophisticated models</p> <p>great for text mining</p> <p>great for sensor data</p> <p>not optimal for the most other educational data</p> <p>Genetic algoriithms</p> <p>uses mutation, combination, and natural selection to search space of possible models/ can produce inconsistent answers</p> <p>Neural networks</p> <p>composes extremely complex realationships through combining perceptrons</p> <p>svm genetic algorithm and neural networks are great for some but not for al</p> <p>&nbsp;</p>; <p>6.1 Learning curves</p> <p>visualization</p> <p>Displaying information in a meaningful fashion</p> <p>induce the viewer to think about what it means</p> <p>avoid distorting what the data have to say</p> <p>Encourage the eye to compare different pieces of data</p> <p>Reveal the data at several levels</p> <p>Visualization</p> <p>A big area</p> <p>Assumptoins</p> <p>The student is practicing the same skill several time in approximately the same fashion/ similar methods and considerations apply to situations where the student is recalling the same knowledge several times</p> <p>LISP learning curve</p> <p>Learning curves- power law of learning; performance (both speed and accuracy) improves with a power function</p> <p>Called power law- speed and accuracy both follow a power curve; radical improvement at first which slows over time towards an asymptote/ passing the asymptote usually involves developing entirely new strategy</p> <p>Fosbury flop-jump</p> <p>Making inference from learning curves</p> <p>via visual inspection of the curve form</p> <p>corbett&amp;anderson- two skills go at the same time</p> <p>uses</p> <p>to study and refine item-skill mappings in educational software</p> <p>&nbsp;</p> <p>&nbsp;</p>; <p>6.3 Scatter plots</p> <p>visualization</p> <p>scatter plots</p> <p>Heat Maps</p> <p>Parameter Space Maps</p> <p>Scatterplot - don't scale large data</p> <p>Heat map - by density, intensity</p> <p>Parameter space maps - special case of heat maps</p> <p>used to look at the goodness of various parameters, particularly for BKT</p> <p>Average graph- literally average graph</p>; <p>6.4 State Space Diagrams</p> <p>Visualizations of all the states that the learning system can have during a problem</p> <p>State= complete characterization of situations</p> <p>Also referred to as student learning pathways or interaction networks</p> <p>game</p> <p>stage1 stage2 stage3 (Refraction)</p> <p>keep changing different states and find the success state</p> <p>Uses</p> <p>study specific student trajectories</p> <p>see which paths end of being productive</p> <p>see which paths are rare (despite being productive)</p> <p>make recommendation hints to students based on their path</p>; <p>7.1 Clustering</p> <p>Clustering - a type of structure discovery algorithm</p> <p>want to find what structure there is among the data points and don't know anything about a priori&nbsp; about the structure</p> <p>group together!</p> <p>k means clustering algorithms - simple</p> <p>centeroids (randomly selected)</p> <p>vonoi diagram - distribute equally</p> <p>refit centerioids</p> <p>convergence do it until fit centeroids</p> <p>&nbsp;</p>; <p>7.2 Validation and selection</p> <p>how we choose value for K?</p> <p>Distortion (Mean squared deviation)</p> <p>Take each point P</p> <p>find the centeroid of P's cluster C</p> <p>Find the distance D from C to P</p> <p>Square D to get D'</p> <p>Sum all D' to get distortion</p> <p>Distance from A to B in two dimensions</p> <p>Works between randomized restarts/ does not work for choosing cluster size</p> <p>Distance to nearest cluster center should almost always be smaller with more clusters</p> <p>It only isn't when you have bad luck in your randomization</p> <p>Cross validation cannot solve this problem - Different problem than prediction modeling; you are determining whether any center is close to a given point</p> <p>Solution - Penalize models with more clusters, according to how much extra fit would be expected from the additional clusters</p> <p>Using an information criterion</p> <p>Assess how much fit would be spuriously expected from a random N centroids ( without allowing&nbsp; the centroids to move)</p> <p>Assess how much fit you actually had</p> <p>Find the differnce</p> <p>So how many clusters?</p> <p>Try several values of K</p> <p>Find best fitting set of clusters for each value of K</p> <p>choose best point</p> <p>&nbsp;</p> <p>&nbsp;</p>"																								1																										SE5DIAI6	videoRecording	2016	Georgia Tech	Cross Validation					https://www.youtube.com/watch?v=sFO2ff-gTh0		9/9/16	9/13/16 16:06	9/13/16 16:06	9/9/16 19:37												Youtube										<p>Predicting values in the testing set</p> <p>if too much fitting in the train set it would not be generalizable since we kind of assume test set is the representative of our world</p> <p>IID independently identically distributed - Fundamental assumption for a lot of organism</p> <p>take some sample from the training data and act like if it is test data and run in order to predict</p> <p>training data divided into folds pick the lowest error one</p>		https://www.youtube.com/watch?v=sFO2ff-gTh0																																																8CJ6XRPB	webpage	2016		Passing the Privacy Test as Student Data Laws Take Effect (EdSurge News)	EdSurge				https://www.edsurge.com/news/2016-01-12-passing-the-privacy-test-as-student-data-laws-take-effect	"On January 1, 2016, “ 	SOPIPA”—the recently passed California student data privacy law that defines how edtech companies can use student data became effective. About 25 other states have passed similar laws that are already in effect, or will become effective.  At the same time, more than 200 sc"	1/12/16	9/20/16 15:24	9/20/16 15:24	9/20/16 15:24																						"<ul> <li>Gov trying to protect students info from company</li> <li>Access, must delete, do not require students to share data unless it is for educational purpose</li> <li> <p>As a student, the SOPIPA law trying to protect California Students' online privacy seems to be appropriate. If the SOPIPA law is effective, how would the company promote their product to a society where research proven results are valued?</p> </li> </ul>"	/Users/JoonyoungPark/Library/Application Support/Zotero/Profiles/dasdr1oy.default/zotero/storage/9IW3G4JV/2016-01-12-passing-the-privacy-test-as-student-data-laws-take-effect.html																																																	G53DSCAQ	webpage			Cluster					https://www.cs.uic.edu/~wilkinson/Applets/cluster.html			10/21/16 4:56	10/21/16 4:56	10/21/16 4:56																						"<p>K-means clustering</p> <p>n data points to k number of clusters by gathering near mean data points</p> <p>define it's goal geometrically k(K-1)/2 cutting planes</p> <p>identify cluster centroids and divide first pick the center randomly, need to update by adding more coordinates of the new point</p> <p>Every time re assigned, so it needs to be updated every trial</p> <p>even if it is chosen randomly, need to pick a point for more centered one</p> <p>We need to know K to determine K</p> <p>one color for normal data only!</p> <p>downfall of k-means clustering: find the center point even if the data is silly and wrong</p>"	/Users/JoonyoungPark/Library/Application Support/Zotero/Profiles/dasdr1oy.default/zotero/storage/ZD9IKMGK/cluster.html																																																	CGAS5FTV	webpage			data-wrangling-cheatsheet - data-wrangling-cheatsheet.pdf					https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf			12/22/16 1:40	12/22/16 1:40	12/22/16 1:40																						"<p>This Cheatsheet really saved our semester.</p> <p>Several note to myself</p> <p>1. The data set cheat sheet is using is about flower so it is not the actual code you can use/ will upload preuploaded data on R.</p> <p>2.Gather...Spread...</p> <p>Need to upload Dplyr/ Tidyr first in the library&nbsp;so you gather the data to spread it as how you want your data to look like. If there are list of students and teachers data and want to look them by their grade, you can use spread function/ Gather is different way; gathering columms into row for one site data analysis (that histogram data assignment7)</p>"	/Users/JoonyoungPark/Library/Application Support/Zotero/Profiles/dasdr1oy.default/zotero/storage/CHS3U2UU/data-wrangling-cheatsheet.html																																																	